<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jonathan.Wei&#39;s Notes</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-08-30T09:16:40.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jonathan.Wei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Spark集成TensorflowOnSpark standalone模式下测试mnist</title>
    <link href="http://yoursite.com/2017/08/30/tensorflow-on-spark-standalone/"/>
    <id>http://yoursite.com/2017/08/30/tensorflow-on-spark-standalone/</id>
    <published>2017-08-30T09:06:01.000Z</published>
    <updated>2017-08-30T09:16:40.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="预先条件"><a href="#预先条件" class="headerlink" title="预先条件"></a>预先条件</h1><p>安装tensorflow环境</p>
<h1 id="下载tensorflowonspark代码"><a href="#下载tensorflowonspark代码" class="headerlink" title="下载tensorflowonspark代码"></a>下载tensorflowonspark代码</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">git <span class="built_in">clone</span> https://github.com/yahoo/TensorFlowOnSpark.git</div><div class="line"><span class="built_in">cd</span> TensorFlowOnSpark</div><div class="line"><span class="built_in">export</span> TFoS_HOME=$(<span class="built_in">pwd</span>)</div></pre></td></tr></table></figure>
<h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><p>这里tensorflowOnSpark中提供了一个脚本用于下载spark，我们直接执行这个命令。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="variable">$&#123;TFoS_HOME&#125;</span>/scripts/<span class="built_in">local</span>-setup-spark.sh</div><div class="line">rm spark-1.6.0-bin-hadoop2.6.tar</div><div class="line"><span class="built_in">export</span> SPARK_HOME=$(<span class="built_in">pwd</span>)/spark-1.6.0-bin-hadoop2.6</div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$&#123;SPARK_HOME&#125;</span>/bin:<span class="variable">$&#123;PATH&#125;</span></div></pre></td></tr></table></figure></p>
<h1 id="安装tensorflow以及tensorflowOnSpark"><a href="#安装tensorflow以及tensorflowOnSpark" class="headerlink" title="安装tensorflow以及tensorflowOnSpark"></a>安装tensorflow以及tensorflowOnSpark</h1><p>这里我们通过pip命令来安装tensorflow以及tensorflowOnSpark，目前最新版本的tensorflow是1.2.x，不过我这边测试是用的0.12.1版本。安装指定tensorflow版本可以通过==${version}来指定。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">sudo pip install tensorflow==0.12.1</div><div class="line">sudo pip install tensorflowonspark</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h1 id="下载mnist数据"><a href="#下载mnist数据" class="headerlink" title="下载mnist数据"></a>下载mnist数据</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">mkdir $&#123;TFoS_HOME&#125;/mnist</div><div class="line">pushd $&#123;TFoS_HOME&#125;/mnist</div><div class="line">curl -O &quot;http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz&quot;</div><div class="line">curl -O &quot;http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz&quot;</div><div class="line">curl -O &quot;http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz&quot;</div><div class="line">curl -O &quot;http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz&quot;</div><div class="line">popd</div></pre></td></tr></table></figure>
<h1 id="运行standalone-spark集群"><a href="#运行standalone-spark集群" class="headerlink" title="运行standalone spark集群"></a>运行standalone spark集群</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">export MASTER=spark://$(hostname):7077</div><div class="line">export SPARK_WORKER_INSTANCES=2</div><div class="line">export CORES_PER_WORKER=1 </div><div class="line">export TOTAL_CORES=$(($&#123;CORES_PER_WORKER&#125;*$&#123;SPARK_WORKER_INSTANCES&#125;)) </div><div class="line">$&#123;SPARK_HOME&#125;/sbin/start-master.sh; $&#123;SPARK_HOME&#125;/sbin/start-slave.sh -c $CORES_PER_WORKER -m 3G $&#123;MASTER&#125;</div></pre></td></tr></table></figure>
<h1 id="测试pyspark、tensorflow以及tensorflowOnSpark"><a href="#测试pyspark、tensorflow以及tensorflowOnSpark" class="headerlink" title="测试pyspark、tensorflow以及tensorflowOnSpark"></a>测试pyspark、tensorflow以及tensorflowOnSpark</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pyspark</div><div class="line">&gt;&gt;&gt; import tensorflow as tf</div><div class="line">&gt;&gt;&gt; from tensorflowonspark import TFCluster</div><div class="line">&gt;&gt;&gt; exit()</div></pre></td></tr></table></figure>
<h1 id="使用spark转换mnist压缩文件"><a href="#使用spark转换mnist压缩文件" class="headerlink" title="使用spark转换mnist压缩文件"></a>使用spark转换mnist压缩文件</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">cd $&#123;TFoS_HOME&#125;</div><div class="line"># rm -rf examples/mnist/csv</div><div class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit \</div><div class="line">--master $&#123;MASTER&#125; \</div><div class="line">$&#123;TFoS_HOME&#125;/examples/mnist/mnist_data_setup.py \</div><div class="line">--output examples/mnist/csv \</div><div class="line">--format csv</div><div class="line">ls -lR examples/mnist/csv</div></pre></td></tr></table></figure>
<h1 id="运行分布式mnist训练（使用feed-dict）"><a href="#运行分布式mnist训练（使用feed-dict）" class="headerlink" title="运行分布式mnist训练（使用feed_dict）"></a>运行分布式mnist训练（使用feed_dict）</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"># rm -rf mnist_model</div><div class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit \</div><div class="line">--master $&#123;MASTER&#125; \</div><div class="line">--py-files $&#123;TFoS_HOME&#125;/examples/mnist/spark/mnist_dist.py \</div><div class="line">--conf spark.cores.max=$&#123;TOTAL_CORES&#125; \</div><div class="line">--conf spark.task.cpus=$&#123;CORES_PER_WORKER&#125; \</div><div class="line">--conf spark.executorEnv.JAVA_HOME=&quot;$JAVA_HOME&quot; \</div><div class="line">$&#123;TFoS_HOME&#125;/examples/mnist/spark/mnist_spark.py \</div><div class="line">--cluster_size $&#123;SPARK_WORKER_INSTANCES&#125; \</div><div class="line">--images examples/mnist/csv/train/images \</div><div class="line">--labels examples/mnist/csv/train/labels \</div><div class="line">--format csv \</div><div class="line">--mode train \</div><div class="line">--model mnist_model</div><div class="line"></div><div class="line">ls -l mnist_model</div></pre></td></tr></table></figure>
<h1 id="运行分布式mnist推论（使用feed-dict）"><a href="#运行分布式mnist推论（使用feed-dict）" class="headerlink" title="运行分布式mnist推论（使用feed_dict）"></a>运行分布式mnist推论（使用feed_dict）</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"># rm -rf predictions</div><div class="line">$&#123;SPARK_HOME&#125;/bin/spark-submit \</div><div class="line">--master $&#123;MASTER&#125; \</div><div class="line">--py-files $&#123;TFoS_HOME&#125;/examples/mnist/spark/mnist_dist.py \</div><div class="line">--conf spark.cores.max=$&#123;TOTAL_CORES&#125; \</div><div class="line">--conf spark.task.cpus=$&#123;CORES_PER_WORKER&#125; \</div><div class="line">--conf spark.executorEnv.JAVA_HOME=&quot;$JAVA_HOME&quot; \</div><div class="line">$&#123;TFoS_HOME&#125;/examples/mnist/spark/mnist_spark.py \</div><div class="line">--cluster_size $&#123;SPARK_WORKER_INSTANCES&#125; \</div><div class="line">--images examples/mnist/csv/test/images \</div><div class="line">--labels examples/mnist/csv/test/labels \</div><div class="line">--mode inference \</div><div class="line">--format csv \</div><div class="line">--model mnist_model \</div><div class="line">--output predictions</div><div class="line"></div><div class="line">less predictions/part-00000</div></pre></td></tr></table></figure>
<p>预测结果如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">2017-02-10T23:29:17.009563 Label: 7, Prediction: 7</div><div class="line">2017-02-10T23:29:17.009677 Label: 2, Prediction: 2</div><div class="line">2017-02-10T23:29:17.009721 Label: 1, Prediction: 1</div><div class="line">2017-02-10T23:29:17.009761 Label: 0, Prediction: 0</div><div class="line">2017-02-10T23:29:17.009799 Label: 4, Prediction: 4</div><div class="line">2017-02-10T23:29:17.009838 Label: 1, Prediction: 1</div><div class="line">2017-02-10T23:29:17.009876 Label: 4, Prediction: 4</div><div class="line">2017-02-10T23:29:17.009914 Label: 9, Prediction: 9</div><div class="line">2017-02-10T23:29:17.009951 Label: 5, Prediction: 6</div><div class="line">2017-02-10T23:29:17.009989 Label: 9, Prediction: 9</div><div class="line">2017-02-10T23:29:17.010026 Label: 0, Prediction: 0</div></pre></td></tr></table></figure></p>
<h1 id="关闭spark集群"><a href="#关闭spark集群" class="headerlink" title="关闭spark集群"></a>关闭spark集群</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$&#123;SPARK_HOME&#125;/sbin/stop-slave.sh; $&#123;SPARK_HOME&#125;/sbin/stop-master.sh</div></pre></td></tr></table></figure>
<p>原链接：<br><a href="https://github.com/yahoo/TensorFlowOnSpark/wiki/GetStarted_standalone" target="_blank" rel="external">https://github.com/yahoo/TensorFlowOnSpark/wiki/GetStarted_standalone</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;预先条件&quot;&gt;&lt;a href=&quot;#预先条件&quot; class=&quot;headerlink&quot; title=&quot;预先条件&quot;&gt;&lt;/a&gt;预先条件&lt;/h1&gt;&lt;p&gt;安装tensorflow环境&lt;/p&gt;
&lt;h1 id=&quot;下载tensorflowonspark代码&quot;&gt;&lt;a href=&quot;#下载tensorflowonspark代码&quot; class=&quot;headerlink&quot; title=&quot;下载tensorflowonspark代码&quot;&gt;&lt;/a&gt;下载tensorflowonspark代码&lt;/h1&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;git &lt;span class=&quot;built_in&quot;&gt;clone&lt;/span&gt; https://github.com/yahoo/TensorFlowOnSpark.git&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;cd&lt;/span&gt; TensorFlowOnSpark&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; TFoS_HOME=$(&lt;span class=&quot;built_in&quot;&gt;pwd&lt;/span&gt;)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h1 id=&quot;安装Spark&quot;&gt;&lt;a href=&quot;#安装Spark&quot; class=&quot;headerlink&quot; title=&quot;安装Spark&quot;&gt;&lt;/a&gt;安装Spark&lt;/h1&gt;&lt;p&gt;这里tensorflowOnSpark中提供了一个脚本用于下载spark，我们直接执行这个命令。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;variable&quot;&gt;$&amp;#123;TFoS_HOME&amp;#125;&lt;/span&gt;/scripts/&lt;span class=&quot;built_in&quot;&gt;local&lt;/span&gt;-setup-spark.sh&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;rm spark-1.6.0-bin-hadoop2.6.tar&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; SPARK_HOME=$(&lt;span class=&quot;built_in&quot;&gt;pwd&lt;/span&gt;)/spark-1.6.0-bin-hadoop2.6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;export&lt;/span&gt; PATH=&lt;span class=&quot;variable&quot;&gt;$&amp;#123;SPARK_HOME&amp;#125;&lt;/span&gt;/bin:&lt;span class=&quot;variable&quot;&gt;$&amp;#123;PATH&amp;#125;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;h1 id=&quot;安装tensorflow以及tensorflowOnSpark&quot;&gt;&lt;a href=&quot;#安装tensorflow以及tensorflowOnSpark&quot; class=&quot;headerlink&quot; title=&quot;安装tensorflow以及tensorflowOnSpark&quot;&gt;&lt;/a&gt;安装tensorflow以及tensorflowOnSpark&lt;/h1&gt;&lt;p&gt;这里我们通过pip命令来安装tensorflow以及tensorflowOnSpark，目前最新版本的tensorflow是1.2.x，不过我这边测试是用的0.12.1版本。安装指定tensorflow版本可以通过==${version}来指定。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;sudo pip install tensorflow==0.12.1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;sudo pip install tensorflowonspark&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="tensorflow" scheme="http://yoursite.com/categories/tensorflow/"/>
    
    
      <category term="tensorflow" scheme="http://yoursite.com/tags/tensorflow/"/>
    
      <category term="spark" scheme="http://yoursite.com/tags/spark/"/>
    
      <category term="standalone" scheme="http://yoursite.com/tags/standalone/"/>
    
  </entry>
  
  <entry>
    <title>使用aiml开发智能聊天机器人</title>
    <link href="http://yoursite.com/2017/08/30/AI-Chat-Bot-in-Python-with-AIML/"/>
    <id>http://yoursite.com/2017/08/30/AI-Chat-Bot-in-Python-with-AIML/</id>
    <published>2017-08-30T08:57:26.000Z</published>
    <updated>2017-08-30T09:17:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="aiml介绍"><a href="#aiml介绍" class="headerlink" title="aiml介绍"></a>aiml介绍</h1><p>AIML是Richard Wallace开发的。 他开发了一个叫A.L.I.C.E（Artificial Linguistics Internet Computer Entity）的机器人并且赢了几个人工智能的奖项。 有趣的是， 其中一个图灵测试是让一个人在文本界面跟一个机器人聊几分钟，看看人们是否认为它是个人类。 AIML是一种定义了匹配模式和决定响应的规则的一种XML。</p>
<p>要看完整的AIML入门，可以看一下 Alice Bot’s AIML Primer.你可以在AIML wiki页学更多关于AIML的知识并知道它能做什么。 我们先写一些AIML文件并用Python给它一点生命。</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip install aiml</div></pre></td></tr></table></figure>
<h1 id="aiml自带简易英文语料库"><a href="#aiml自带简易英文语料库" class="headerlink" title="aiml自带简易英文语料库"></a>aiml自带简易英文语料库</h1><p>Python aiml安装完成后在Python安装目录下的 site-packages/aiml下会有alice子目录，这个是系统自带的一个简单的语料库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">alice</div><div class="line">standard</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h1 id="创建标准启动文件-std-startup-xml"><a href="#创建标准启动文件-std-startup-xml" class="headerlink" title="创建标准启动文件 std-startup.xml"></a>创建标准启动文件 std-startup.xml</h1><p>std-startup.xml用于加载aiml文件到大脑。<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">aiml</span> <span class="attr">version</span>=<span class="string">"1.0.1"</span> <span class="attr">encoding</span>=<span class="string">"UTF-8"</span>&gt;</span></div><div class="line">    <span class="comment">&lt;!-- std-startup.xml --&gt;</span></div><div class="line"></div><div class="line">    <span class="comment">&lt;!-- Category is an atomic AIML unit --&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">category</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="comment">&lt;!-- Pattern to match in user input --&gt;</span></div><div class="line">        <span class="comment">&lt;!-- If user enters "LOAD AIML B" --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>LOAD AIML B<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="comment">&lt;!-- Template is the response to the pattern --&gt;</span></div><div class="line">        <span class="comment">&lt;!-- This learn an aiml file --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">template</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">learn</span>&gt;</span>basic_chat.aiml<span class="tag">&lt;/<span class="name">learn</span>&gt;</span></div><div class="line">            <span class="comment">&lt;!-- You can add more aiml files here --&gt;</span></div><div class="line">            <span class="comment">&lt;!--&lt;learn&gt;more_aiml.aiml&lt;/learn&gt;--&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">template</span>&gt;</span></div><div class="line">        </div><div class="line">    <span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">aiml</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>注：采用learn标签来学习aiml文件。这里通过load aiml b命令来匹配，当用户输入这个命令的时候会自动执行重新加载操作。匹配多个aiml文件可以将配置改成 *.aiml</p>
<h1 id="创建aiml文件"><a href="#创建aiml文件" class="headerlink" title="创建aiml文件"></a>创建aiml文件</h1><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">aiml</span> <span class="attr">version</span>=<span class="string">"1.0.1"</span> <span class="attr">encoding</span>=<span class="string">"UTF-8"</span>&gt;</span></div><div class="line"><span class="comment">&lt;!-- basic_chat.aiml --&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">category</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>HELLO<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">template</span>&gt;</span></div><div class="line">            Well, hello!</div><div class="line">        <span class="tag">&lt;/<span class="name">template</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line">    </div><div class="line">    <span class="tag">&lt;<span class="name">category</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>WHAT ARE YOU<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">template</span>&gt;</span></div><div class="line">            I'm a bot, silly!</div><div class="line">        <span class="tag">&lt;/<span class="name">template</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">category</span>&gt;</span></div><div class="line">    </div><div class="line"><span class="tag">&lt;/<span class="name">aiml</span>&gt;</span></div></pre></td></tr></table></figure>
<p>注：pattern标签中，英文必须大写</p>
<h1 id="随机响应"><a href="#随机响应" class="headerlink" title="随机响应"></a>随机响应</h1><p>相信这个大伙都是很容易理解的，就是随机从中抽取一个答案回答用户<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">category</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">pattern</span>&gt;</span>ONE TIME I *<span class="tag">&lt;/<span class="name">pattern</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">template</span>&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">random</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>Go on.<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>How old are you?<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>Be more specific.<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>I did not know that.<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>Are you telling the truth?<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>I don't know what that means.<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>Try to tell me that another way.<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>Are you talking about an animal, vegetable or mineral?<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>What is it?<span class="tag">&lt;/<span class="name">li</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">random</span>&gt;</span></div><div class="line">    <span class="tag">&lt;/<span class="name">template</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">category</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h1 id="使用已存在的aiml"><a href="#使用已存在的aiml" class="headerlink" title="使用已存在的aiml"></a>使用已存在的aiml</h1><p>编写你自己的AIML文件是一个很有趣的事，但是它将花费很大的功夫。我觉得它需要大概10,000个模式才会开始变得真实起来。幸运的是，ALICE基金会提供了大量免费的AIML文件。在<a href="http://www.alicebot.org/aiml/aaa/" target="_blank" rel="external">Alice Bot website</a>上浏览AIML文件。</p>
<h1 id="新建一个机器人"><a href="#新建一个机器人" class="headerlink" title="新建一个机器人"></a>新建一个机器人</h1><p>这里我们就不累赘这个过程讲解了，如果想了解可以看下面的参考链接，这里我们直接上最终代码</p>
<h2 id="启动程序"><a href="#启动程序" class="headerlink" title="启动程序"></a>启动程序</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div></pre></td><td class="code"><pre><div class="line"># -*- coding: utf-8 -*-</div><div class="line">import aiml</div><div class="line">import os</div><div class="line"></div><div class="line"></div><div class="line">mybot_path = &apos;./Alice&apos;</div><div class="line">#切换到语料库所在工作目录</div><div class="line">os.chdir(mybot_path)</div><div class="line"></div><div class="line">mybot = aiml.Kernel()</div><div class="line"></div><div class="line">sessionId = &quot;&quot;</div><div class="line">#Get session info as dictionary. Contains the input</div><div class="line"># and output history as well as any predicates known</div><div class="line">#sessionData = mybot.getSessionData(sessionId)</div><div class="line"></div><div class="line"># Each session ID needs to be a unique value</div><div class="line"># The predicate name is the name of something/someone</div><div class="line"># that the bot knows about in your session with the bot</div><div class="line"># The bot might know you as &quot;Billy&quot; and that your &quot;dog&quot; is named &quot;Brandy&quot;</div><div class="line">#mybot.setPredicate(&quot;dog&quot;, &quot;Brandy&quot;, sessionId)</div><div class="line">#mybot.setBotPredicate(&quot;hometown&quot;, &quot;127.0.0.1&quot;)</div><div class="line"></div><div class="line">if os.path.isfile(&quot;chatbot_brain.brn&quot;):</div><div class="line">    mybot.bootstrap(brainFile=&quot;chat_brain.brn&quot;)</div><div class="line">else:</div><div class="line">    mybot.bootstrap(learnFiles=&quot;std-startup.xml&quot;, commands=&quot;load aiml b&quot;)</div><div class="line">    mybot.saveBrain(&quot;chatbot_brain.brn&quot;)</div><div class="line"></div><div class="line">while True:</div><div class="line">    message = raw_input(&quot;Enter your message &gt;&gt; &quot;)</div><div class="line">    if &quot;session&quot; in message:</div><div class="line">        sessionId = message</div><div class="line">        sessionData = mybot.getSessionData(sessionId)</div><div class="line">    elif message == &quot;quit&quot;:</div><div class="line">        exit()</div><div class="line">    elif message == &quot;save&quot;:</div><div class="line">        mybot.saveBrain(&quot;vigorbot_brain.brn&quot;)</div><div class="line">    else:</div><div class="line">        bot_response = mybot.respond(message,sessionId)</div><div class="line">        #Do something with bot_response</div><div class="line">        print(bot_response)</div></pre></td></tr></table></figure>
<p>这里为了做测试我做了下修改，通过输入包含session字符串信息来设置session，测试session记录信息的分离，我们来看下测试结果<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">Enter your message &gt;&gt; session1</div><div class="line">Enter your message &gt;&gt; My dogs name is Max</div><div class="line">That is interesting that you have a dog named Max</div><div class="line">Enter your message &gt;&gt; What is my dogs name?</div><div class="line">Your dog&apos;s name is Max.</div><div class="line">Enter your message &gt;&gt;</div><div class="line"></div><div class="line">Enter your message &gt;&gt; session2</div><div class="line">Enter your message &gt;&gt; My dogs name is Max2</div><div class="line">That is interesting that you have a dog named Max2</div><div class="line">Enter your message &gt;&gt; What is my dogs name?</div><div class="line">Your dog&apos;s name is Max2.</div><div class="line">Enter your message &gt;&gt;</div><div class="line"></div><div class="line">Enter your message &gt;&gt; session1</div><div class="line">Enter your message &gt;&gt; What is my dogs name?</div><div class="line">Your dog&apos;s name is Max.</div><div class="line"></div><div class="line">Enter your message &gt;&gt; session2</div><div class="line">Enter your message &gt;&gt; What is my dogs name?</div><div class="line">Your dog&apos;s name is Max2.</div></pre></td></tr></table></figure></p>
<p>看我们的session分离的效果出来了。但是很遗憾的是，当我save之后关闭程序重新启动，session的信息并没有被保存下来。</p>
<h1 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h1><ul>
<li>中文aiml语料库过少，人工制作语料库成本太高</li>
<li>session信息并未作保存，这个是需要自己去优化修改的</li>
</ul>
<p>参考链接：<br><a href="http://www.devdungeon.com/content/ai-chat-bot-python-aiml" target="_blank" rel="external">http://www.devdungeon.com/content/ai-chat-bot-python-aiml</a><br><a href="https://www.pandorabots.com/botmaster/en/tutorial" target="_blank" rel="external">https://www.pandorabots.com/botmaster/en/tutorial</a><br><a href="http://www.alicebot.org/aiml/aaa/" target="_blank" rel="external">http://www.alicebot.org/aiml/aaa/</a><br><a href="https://www.biaodianfu.com/python-aiml.html" target="_blank" rel="external">https://www.biaodianfu.com/python-aiml.html</a><br><a href="http://www.alicebot.org/documentation/aiml101.html" target="_blank" rel="external">http://www.alicebot.org/documentation/aiml101.html</a><br><a href="https://www.tutorialspoint.com/aiml/index.htm" target="_blank" rel="external">https://www.tutorialspoint.com/aiml/index.htm</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;aiml介绍&quot;&gt;&lt;a href=&quot;#aiml介绍&quot; class=&quot;headerlink&quot; title=&quot;aiml介绍&quot;&gt;&lt;/a&gt;aiml介绍&lt;/h1&gt;&lt;p&gt;AIML是Richard Wallace开发的。 他开发了一个叫A.L.I.C.E（Artificial Linguistics Internet Computer Entity）的机器人并且赢了几个人工智能的奖项。 有趣的是， 其中一个图灵测试是让一个人在文本界面跟一个机器人聊几分钟，看看人们是否认为它是个人类。 AIML是一种定义了匹配模式和决定响应的规则的一种XML。&lt;/p&gt;
&lt;p&gt;要看完整的AIML入门，可以看一下 Alice Bot’s AIML Primer.你可以在AIML wiki页学更多关于AIML的知识并知道它能做什么。 我们先写一些AIML文件并用Python给它一点生命。&lt;/p&gt;
&lt;h1 id=&quot;安装&quot;&gt;&lt;a href=&quot;#安装&quot; class=&quot;headerlink&quot; title=&quot;安装&quot;&gt;&lt;/a&gt;安装&lt;/h1&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;pip install aiml&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h1 id=&quot;aiml自带简易英文语料库&quot;&gt;&lt;a href=&quot;#aiml自带简易英文语料库&quot; class=&quot;headerlink&quot; title=&quot;aiml自带简易英文语料库&quot;&gt;&lt;/a&gt;aiml自带简易英文语料库&lt;/h1&gt;&lt;p&gt;Python aiml安装完成后在Python安装目录下的 site-packages/aiml下会有alice子目录，这个是系统自带的一个简单的语料库。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;alice&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;standard&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="aiml" scheme="http://yoursite.com/categories/aiml/"/>
    
    
      <category term="aiml" scheme="http://yoursite.com/tags/aiml/"/>
    
      <category term="chatbot" scheme="http://yoursite.com/tags/chatbot/"/>
    
      <category term="ai" scheme="http://yoursite.com/tags/ai/"/>
    
  </entry>
  
  <entry>
    <title>Apache beam - Pipeline设计</title>
    <link href="http://yoursite.com/2017/06/16/design-your-pipeline/"/>
    <id>http://yoursite.com/2017/06/16/design-your-pipeline/</id>
    <published>2017-06-16T09:30:12.000Z</published>
    <updated>2017-08-30T09:19:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="设计Pipeline时需要考虑什么？"><a href="#设计Pipeline时需要考虑什么？" class="headerlink" title="设计Pipeline时需要考虑什么？"></a>设计Pipeline时需要考虑什么？</h2><p>当我们设计我们的beam pipeline时，需要考虑的一些基础问题：</p>
<ul>
<li>你的输入数据存储在哪里？这将决定<strong><em>Read</em></strong>在pipeline开始时需要使用哪些类型的转换</li>
<li>你的数据是怎么样的？</li>
<li>你想用数据做什么？</li>
<li>你的输出数据是什么样的，应该存储到哪里？这个决定<strong><em>write</em></strong>在pipeline末端使用哪些类型的transforms</li>
</ul>
<h2 id="一条基本的Pipeline"><a href="#一条基本的Pipeline" class="headerlink" title="一条基本的Pipeline"></a>一条基本的Pipeline</h2><p>最简单的Pipeline体现为一个线性的操作流程。如下图<br><img src="/images/design-your-pipeline-linear.png" alt="img"><br><a id="more"></a><br>但是，在实际场景中，Pipeline比基本的Pipeline要复杂的多。Pipeline代表一个有步骤的有向无环图。它可能有多个输入源，多个输出接收器，并且其操作PTransforms可以读取和输出多个PCollections。</p>
<h2 id="分支PCollections"><a href="#分支PCollections" class="headerlink" title="分支PCollections"></a>分支PCollections</h2><div class="note info"><p>重要的是要了解Transforms不消耗PCollections，相反，他们认为每一个独立的元素都是一个PCollection，且创建一个新的PCollection用于输出。这样，我们就可以对同一个PCollection中的不同元素做不同的操作。</p>
</div>
<h3 id="多个PTransforms处理相同的PCollections"><a href="#多个PTransforms处理相同的PCollections" class="headerlink" title="多个PTransforms处理相同的PCollections"></a>多个PTransforms处理相同的PCollections</h3><p>可以使用相同的PCollection输入用于多个转换，而不消耗输入或更改它。<br>图中所示的流水线从单个数据库源读取输入数据，并创建一个PCollection表行。然后，Pipeline将多个transforms应用到同一个PCollection。转换a读取所有以A字母开头的PCollection，转换b读取所有以B开头的PCollection。转换a与转换b的输入是同一个PCollection<br><img src="/images/design-your-pipeline-multiple-pcollections.png" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;String&gt; dbRowCollection = ...;</div><div class="line"></div><div class="line">PCollection&lt;String&gt; aCollection = dbRowCollection.apply(<span class="string">"aTrans"</span>, ParDo.of(<span class="keyword">new</span> DoFn&lt;String, String&gt;()&#123;</div><div class="line">  <span class="meta">@ProcessElement</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(ProcessContext c)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span>(c.element().startsWith(<span class="string">"A"</span>))&#123;</div><div class="line">      c.output(c.element());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;));</div><div class="line"></div><div class="line">PCollection&lt;String&gt; bCollection = dbRowCollection.apply(<span class="string">"bTrans"</span>, ParDo.of(<span class="keyword">new</span> DoFn&lt;String, String&gt;()&#123;</div><div class="line">  <span class="meta">@ProcessElement</span></div><div class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(ProcessContext c)</span> </span>&#123;</div><div class="line">    <span class="keyword">if</span>(c.element().startsWith(<span class="string">"B"</span>))&#123;</div><div class="line">      c.output(c.element());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;));</div></pre></td></tr></table></figure></p>
<h3 id="单个PTransforms产生多个输出"><a href="#单个PTransforms产生多个输出" class="headerlink" title="单个PTransforms产生多个输出"></a>单个PTransforms产生多个输出</h3><p>分支管道的另一种方法是通过使用带标签的输出将单个变换输出转换为多个。转换产生超过一个的输出处理输入中的每一个元素，以及输出0到多个PCollections<br>下面的图3示出了上述相同的示例，但是是一个转换产生多个输出。以“A”开头的名称将添加到主输出中PCollection，以“B”开头的名称将添加到其他输出PCollection。<br><img src="/images/design-your-pipeline-additional-outputs.png" alt="img"><br>图2中的Pipeline包含两个处理相同PCollection元素的转换，一个转换使用以下逻辑：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>（以<span class="string">'A'</span>开头）&#123;outputToPCollectionA&#125;</div></pre></td></tr></table></figure></p>
<p>而另一个转换则是：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>（以<span class="string">'B'</span>开头）&#123;outputToPCollectionB&#125;</div></pre></td></tr></table></figure></p>
<p>因为每个转换都读取整个PCollection，所以PCollection中的每个元素都被处理两次。<br>图3中的Pipeline以不同的方式执行相同的操作。下面的逻辑只使用一个转换<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>（以<span class="string">'A'</span>开头）&#123;outputToPCollectionA&#125; <span class="keyword">else</span> <span class="keyword">if</span>（以<span class="string">'B'</span>开头）&#123;outputToPCollectionB&#125;</div></pre></td></tr></table></figure></p>
<p>其中输入PCollection中的每个元素<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Define two TupleTags, one for each output.</span></div><div class="line"><span class="keyword">final</span> TupleTag&lt;String&gt; startsWithATag = <span class="keyword">new</span> TupleTag&lt;String&gt;()&#123;&#125;;</div><div class="line"><span class="keyword">final</span> TupleTag&lt;String&gt; startsWithBTag = <span class="keyword">new</span> TupleTag&lt;String&gt;()&#123;&#125;;</div><div class="line"></div><div class="line">PCollectionTuple mixedCollection =</div><div class="line">    dbRowCollection.apply(ParDo</div><div class="line">        .of(<span class="keyword">new</span> DoFn&lt;String, String&gt;() &#123;</div><div class="line">          <span class="meta">@ProcessElement</span></div><div class="line">          <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processElement</span><span class="params">(ProcessContext c)</span> </span>&#123;</div><div class="line">            <span class="keyword">if</span> (c.element().startsWith(<span class="string">"A"</span>)) &#123;</div><div class="line">              <span class="comment">// Emit to main output, which is the output with tag startsWithATag.</span></div><div class="line">              c.output(c.element());</div><div class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span>(c.element().startsWith(<span class="string">"B"</span>)) &#123;</div><div class="line">              <span class="comment">// Emit to output with tag startsWithBTag.</span></div><div class="line">              c.output(startsWithBTag, c.element());</div><div class="line">            &#125;</div><div class="line">          &#125;</div><div class="line">        &#125;)</div><div class="line">        <span class="comment">// Specify main output. In this example, it is the output</span></div><div class="line">        <span class="comment">// with tag startsWithATag.</span></div><div class="line">        .withOutputTags(startsWithATag,</div><div class="line">        <span class="comment">// Specify the output with tag startsWithBTag, as a TupleTagList.</span></div><div class="line">                        TupleTagList.of(startsWithBTag)));</div><div class="line"></div><div class="line"><span class="comment">// Get subset of the output with tag startsWithATag.</span></div><div class="line">mixedCollection.get(startsWithATag).apply(...);</div><div class="line"></div><div class="line"><span class="comment">// Get subset of the output with tag startsWithBTag.</span></div><div class="line">mixedCollection.get(startsWithBTag).apply(...);</div></pre></td></tr></table></figure></p>
<p>您可以使用任一机制来产生多个输出PCollection。然而，如果变换的每个元素的计算是耗时的，则使用额外的输出更有意义</p>
<h3 id="合并PCollections"><a href="#合并PCollections" class="headerlink" title="合并PCollections"></a>合并PCollections</h3><p>通常，通过多次转换将PCollection分成多个PCollections后，您将需要将部分或全部PCollections合并在一起。 您可以使用以下方法之一：</p>
<ul>
<li>Flatten - 您可以使用Beam SDK中的Flatten变换来合并多个相同类型的PCollections。</li>
<li>Join - 您可以使用Beam SDK中的CoGroupByKey变换来执行两个PCollections之间的关系连接。 PCollections必须键入（即它们必须是键/值对的集合），并且它们必须使用相同的键类型。</li>
</ul>
<p>下图中，在分成两个PCollections之后，一个名字以’A’开头，一个名字以’B’开头，管道将两个合并成一个PCollection，现在包含以“A”或“B”。 在这里，使用Flatten是合理的，因为合并的PCollections都包含相同的类型。<br><img src="/images/design-your-pipeline-flatten.png" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line"><span class="comment">//merge the two PCollections with Flatten</span></div><div class="line">PCollectionList&lt;String&gt; collectionList = PCollectionList.of(aCollection).and(bCollection);</div><div class="line">PCollection&lt;String&gt; mergedCollectionWithFlatten = collectionList</div><div class="line">    .apply(Flatten.&lt;String&gt;pCollections());</div><div class="line"></div><div class="line"><span class="comment">// continue with the new merged PCollection     </span></div><div class="line">mergedCollectionWithFlatten.apply(...);</div></pre></td></tr></table></figure></p>
<h3 id="多个来源"><a href="#多个来源" class="headerlink" title="多个来源"></a>多个来源</h3><p>管道可以从一个或多个来源读取其输入。 如果管道从多个来源读取，并且来自这些来源的数据是相关的，则可以将输入连接在一起。 在下图所示的示例中，管道从数据库表中读取名称和地址，以及从Kafka主题读取名称和订单号。 然后，管道使用CoGroupByKey来加入这个信息，其中的关键是名称; 结果PCollection包含名称，地址和订单的所有组合。<br><img src="/images/design-your-pipeline-join.png" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String, String&gt;&gt; userAddress = pipeline.apply(JdbcIO.&lt;KV&lt;String, String&gt;&gt;read()...);</div><div class="line"></div><div class="line">PCollection&lt;KV&lt;String, String&gt;&gt; userOrder = pipeline.apply(KafkaIO.&lt;String, String&gt;read()...);</div><div class="line"></div><div class="line"><span class="keyword">final</span> TupleTag&lt;String&gt; addressTag = <span class="keyword">new</span> TupleTag&lt;String&gt;();</div><div class="line"><span class="keyword">final</span> TupleTag&lt;String&gt; orderTag = <span class="keyword">new</span> TupleTag&lt;String&gt;();</div><div class="line"></div><div class="line"><span class="comment">// Merge collection values into a CoGbkResult collection.</span></div><div class="line">PCollection&lt;KV&lt;String, CoGbkResult&gt;&gt; joinedCollection =</div><div class="line">  KeyedPCollectionTuple.of(addressTag, userAddress)</div><div class="line">                       .and(orderTag, userOrder)</div><div class="line">                       .apply(CoGroupByKey.&lt;String&gt;create());</div><div class="line"></div><div class="line">coGbkResultCollection.apply(...);</div></pre></td></tr></table></figure></p>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/pipelines/design-your-pipeline/" target="_blank" rel="external">https://beam.apache.org/documentation/pipelines/design-your-pipeline/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;设计Pipeline时需要考虑什么？&quot;&gt;&lt;a href=&quot;#设计Pipeline时需要考虑什么？&quot; class=&quot;headerlink&quot; title=&quot;设计Pipeline时需要考虑什么？&quot;&gt;&lt;/a&gt;设计Pipeline时需要考虑什么？&lt;/h2&gt;&lt;p&gt;当我们设计我们的beam pipeline时，需要考虑的一些基础问题：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;你的输入数据存储在哪里？这将决定&lt;strong&gt;&lt;em&gt;Read&lt;/em&gt;&lt;/strong&gt;在pipeline开始时需要使用哪些类型的转换&lt;/li&gt;
&lt;li&gt;你的数据是怎么样的？&lt;/li&gt;
&lt;li&gt;你想用数据做什么？&lt;/li&gt;
&lt;li&gt;你的输出数据是什么样的，应该存储到哪里？这个决定&lt;strong&gt;&lt;em&gt;write&lt;/em&gt;&lt;/strong&gt;在pipeline末端使用哪些类型的transforms&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;一条基本的Pipeline&quot;&gt;&lt;a href=&quot;#一条基本的Pipeline&quot; class=&quot;headerlink&quot; title=&quot;一条基本的Pipeline&quot;&gt;&lt;/a&gt;一条基本的Pipeline&lt;/h2&gt;&lt;p&gt;最简单的Pipeline体现为一个线性的操作流程。如下图&lt;br&gt;&lt;img src=&quot;/images/design-your-pipeline-linear.png&quot; alt=&quot;img&quot;&gt;&lt;br&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>Apache beam - 创建Pipeline</title>
    <link href="http://yoursite.com/2017/06/16/create-your-pipeline/"/>
    <id>http://yoursite.com/2017/06/16/create-your-pipeline/</id>
    <published>2017-06-16T09:29:49.000Z</published>
    <updated>2017-06-23T01:50:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>Beam程序从头到尾表达了一个数据处理流程。这里介绍在Beam SDK中使用类构建管道的机制。要使用Beam SDK中的类构建管道，您的程序将需要执行以下一般步骤：</p>
<ul>
<li>创建一个<strong><em>Pipeline</em></strong>对象</li>
<li>使用<strong><em>Read</em></strong>或者<strong><em>Create</em></strong>转换去为管道数据创建一个或多个<strong><em>PCollections</em></strong></li>
<li>应用Transforms到每个PCollection.Transforms可以对PCollection中的每个元素进行修改，过滤，分组，解析以及其他处理</li>
<li>最后使用Write或者其他输出方式，完成PCollection的转换</li>
<li>运行Pipeline<a id="more"></a>
<h2 id="创建Pipeline对象"><a href="#创建Pipeline对象" class="headerlink" title="创建Pipeline对象"></a>创建Pipeline对象</h2><div class="note info"><p> 一个beam程序通常从创建Pipeline对象开始<br>在Beam SDK中，一个Pipeline都以明确的类型对象表示Pipeline。每个Pipeline对象是一个独立的实体。它封装了Pipeline运行的数据和应用于该数据的转换。</p>
</div>
创建一个Pipeline，需要声明一个Pipeline对象，并通过它传递一些配置参数。<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Start by defining the options for the pipeline.</span></div><div class="line">PipelineOptions options = PipelineOptionsFactory.create();</div><div class="line"></div><div class="line"><span class="comment">// Then create the pipeline.</span></div><div class="line">Pipeline p = Pipeline.create(options);</div></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="将数据读取进管道"><a href="#将数据读取进管道" class="headerlink" title="将数据读取进管道"></a>将数据读取进管道</h2><div class="note info"><p> 创建Pipeline并初始化PCollection，应用root转换到pipeline对象。一个root转换从外部数据源或指定的某些本地数据创建一个PCollection。<br>Beam SDK包含两种root转换：Read和Create。Read转换从外部数据(例如文本文件或数据库表)源读取数据。Create转换从java.util.Collection内存创建一个PCollection</p>
</div>
<p>以下示例代码显示了如何apply的TextIO.Read root转换从文本文件中读取数据。该转换应用于一个Pipeline对象p，并返回一个类型为PCollection<string>的流水线数据集<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;String&gt; lines = p.apply(</div><div class="line">  <span class="string">"ReadLines"</span>, TextIO.read().from(<span class="string">"gs://some/inputData.txt"</span>));</div></pre></td></tr></table></figure></string></p>
<h2 id="应用转换处理Pipeline数据"><a href="#应用转换处理Pipeline数据" class="headerlink" title="应用转换处理Pipeline数据"></a>应用转换处理Pipeline数据</h2><div class="note info"><p>这里我们可以使用Beam SDK提供的各种转换操作数据。通过PCollection的apply方法处理每一个PCollection并所需的转换对象作为参数进行传递，将转换应用于Pipeline。</p>
</div>
<p>以下的示例代码演示了如何应用一个转换到类型为string的PCollection上。<br>用户定义的自定义变换，它可以反转每个字符串的内容，并输出一个包含反转字符串的PCollection新变量</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;String&gt; words = ...;</div><div class="line">PCollection&lt;String&gt; reversedWords = words.apply(<span class="keyword">new</span> ReverseWords());</div></pre></td></tr></table></figure>
<h2 id="写入或输出最终管道数据"><a href="#写入或输出最终管道数据" class="headerlink" title="写入或输出最终管道数据"></a>写入或输出最终管道数据</h2><div class="note info"><p>应用所有的转换之后，你需要将计算结果进行输出。输出Pipeline最终的<strong><em>PCollections</em></strong>，可以使用<strong><em>Write</em></strong>转换进行操作。<strong><em>Write</em></strong>转换可以输出每一个<strong><em>PCollection</em></strong>到一个外部data sink，例如数据库表。你可以在pipeline中通过<strong><em>Write</em></strong>输出<strong><em>PCollection</em></strong>，通常会在pipeline末端写出数据。</p>
</div>
<p>下面的示例代码演示了如何apply一个<strong><em>TextIO.Write</em></strong>转换将<strong><em>PCollection</em></strong>的String文本写入到文件：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;String&gt; filteredWords = ...;</div><div class="line"></div><div class="line">filteredWords.apply(<span class="string">"WriteMyFile"</span>, TextIO.write().to(<span class="string">"gs://some/outputData.txt"</span>));</div></pre></td></tr></table></figure></p>
<h2 id="运行Pipeline"><a href="#运行Pipeline" class="headerlink" title="运行Pipeline"></a>运行Pipeline</h2><p>构建完Pipeline后，可以采用run方法运行。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p.run();</div></pre></td></tr></table></figure></p>
<p>run方法是异步的。如果想要同步运行，可以在run方法后面添加waitUntilFinish方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">p.run().waitUntilFinish();</div></pre></td></tr></table></figure></p>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/pipelines/create-your-pipeline/" target="_blank" rel="external">https://beam.apache.org/documentation/pipelines/create-your-pipeline/</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Beam程序从头到尾表达了一个数据处理流程。这里介绍在Beam SDK中使用类构建管道的机制。要使用Beam SDK中的类构建管道，您的程序将需要执行以下一般步骤：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;创建一个&lt;strong&gt;&lt;em&gt;Pipeline&lt;/em&gt;&lt;/strong&gt;对象&lt;/li&gt;
&lt;li&gt;使用&lt;strong&gt;&lt;em&gt;Read&lt;/em&gt;&lt;/strong&gt;或者&lt;strong&gt;&lt;em&gt;Create&lt;/em&gt;&lt;/strong&gt;转换去为管道数据创建一个或多个&lt;strong&gt;&lt;em&gt;PCollections&lt;/em&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;应用Transforms到每个PCollection.Transforms可以对PCollection中的每个元素进行修改，过滤，分组，解析以及其他处理&lt;/li&gt;
&lt;li&gt;最后使用Write或者其他输出方式，完成PCollection的转换&lt;/li&gt;
&lt;li&gt;运行Pipeline
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam IO - KafkaIO</title>
    <link href="http://yoursite.com/2017/06/09/apache-beam-kafka-io-sample/"/>
    <id>http://yoursite.com/2017/06/09/apache-beam-kafka-io-sample/</id>
    <published>2017-06-09T02:20:48.000Z</published>
    <updated>2017-06-15T09:31:29.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前在网上看到这样一个例子<br><a href="https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java" target="_blank" rel="external">https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java</a><br>但是从代码的设计上看对flink kafka存在依赖，而这样编写代码我觉得违背了apache beam的初衷，下面我自己写了一个很简单的例子，从kafka input-topic读取数据，写入kafka output-topic。<br>这里我只是做一个简单测试，所以使用的都是单机模式的kafka、zookeeper和flink</p>
<h2 id="公共参数"><a href="#公共参数" class="headerlink" title="公共参数"></a>公共参数</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> WINDOW_SIZE = <span class="number">10</span>;</div><div class="line"><span class="comment">// Default window duration in seconds</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> SLIDE_SIZE = <span class="number">5</span>;</div><div class="line"><span class="comment">// Default window slide in seconds</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_TOPIC = <span class="string">"input-topic"</span>;</div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_OUTPUT_TOPIC = <span class="string">"output-topic"</span>;</div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_BROKER = <span class="string">"localhost:9092"</span>;</div><div class="line"><span class="comment">// Default kafka broker to contact</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String GROUP_ID = <span class="string">"beamGroup"</span>; <span class="comment">// Default groupId</span></div><div class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ZOOKEEPER = <span class="string">"localhost:2181"</span>;</div></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="创建option"><a href="#创建option" class="headerlink" title="创建option"></a>创建option</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">KafkaOptions</span> <span class="keyword">extends</span> <span class="title">PipelineOptions</span> </span>&#123;</div><div class="line">        <span class="meta">@Description</span>(<span class="string">"Sliding window duration, in seconds"</span>)</div><div class="line">        <span class="meta">@Default</span>.Long(WINDOW_SIZE)</div><div class="line">        <span class="function">Long <span class="title">getWindowSize</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setWindowSize</span><span class="params">(Long value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"Window slide, in seconds"</span>)</div><div class="line">        <span class="meta">@Default</span>.Long(SLIDE_SIZE)</div><div class="line">        <span class="function">Long <span class="title">getSlide</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setSlide</span><span class="params">(Long value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka topic to read from"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_TOPIC)</div><div class="line">        <span class="function">String <span class="title">getKafkaTopic</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setKafkaTopic</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka topic to write to"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_OUTPUT_TOPIC)</div><div class="line">        <span class="function">String <span class="title">getOutputKafkaTopic</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setOutputKafkaTopic</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka Broker to read from"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_BROKER)</div><div class="line">        <span class="function">String <span class="title">getBroker</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setBroker</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Zookeeper server to connect to"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(ZOOKEEPER)</div><div class="line">        <span class="function">String <span class="title">getZookeeper</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setZookeeper</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The groupId"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(GROUP_ID)</div><div class="line">        <span class="function">String <span class="title">getGroup</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setGroup</span><span class="params">(String value)</span></span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="KafkaIO-Read"><a href="#KafkaIO-Read" class="headerlink" title="KafkaIO Read"></a>KafkaIO Read</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">KafkaIO.&lt;Long, String&gt;read()</div><div class="line">                   .withBootstrapServers(<span class="string">"localhost:9092"</span>)</div><div class="line">                   .withTopic(KAFKA_TOPIC)  <span class="comment">// use withTopics(List&lt;String&gt;) to read from multiple topics.</span></div><div class="line">                   .withKeyDeserializer(LongDeserializer.class)</div><div class="line">                   .withValueDeserializer(StringDeserializer.class)</div><div class="line">                   .withoutMetadata() <span class="comment">// PCollection&lt;KV&lt;String, String&gt;&gt;</span></div></pre></td></tr></table></figure>
<h2 id="KafkaIO-Write"><a href="#KafkaIO-Write" class="headerlink" title="KafkaIO Write"></a>KafkaIO Write</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">KafkaIO.&lt;Long, String&gt;write()</div><div class="line">                    .withBootstrapServers(<span class="string">"localhost:9092"</span>)</div><div class="line">                    .withTopic(KAFKA_OUTPUT_TOPIC)</div><div class="line">                    .withKeySerializer(LongSerializer.class)</div><div class="line">                    .withValueSerializer(StringSerializer.class)</div><div class="line">                    <span class="comment">// you can further customize KafkaProducer used to write the records by adding more</span></div><div class="line">                    <span class="comment">// settings for ProducerConfig. e.g, to enable compression :</span></div><div class="line">                    <span class="comment">//.updateProducerProperties(ImmutableMap.of("compression.type", "gzip"))</span></div></pre></td></tr></table></figure>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> com.exmind.beam;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.Pipeline;</div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.io.kafka.KafkaIO;</div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.Default;</div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.Description;</div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.PipelineOptions;</div><div class="line"><span class="keyword">import</span> org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.LongDeserializer;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.LongSerializer;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer;</div><div class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringSerializer;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">App</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> WINDOW_SIZE = <span class="number">10</span>;</div><div class="line">    <span class="comment">// Default window duration in seconds</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> SLIDE_SIZE = <span class="number">5</span>;</div><div class="line">    <span class="comment">// Default window slide in seconds</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_TOPIC = <span class="string">"input-topic"</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_OUTPUT_TOPIC = <span class="string">"output-topic"</span>;</div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_BROKER = <span class="string">"localhost:9092"</span>;</div><div class="line">    <span class="comment">// Default kafka broker to contact</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String GROUP_ID = <span class="string">"beamGroup"</span>; <span class="comment">// Default groupId</span></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ZOOKEEPER = <span class="string">"localhost:2181"</span>;</div><div class="line"></div><div class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">KafkaOptions</span> <span class="keyword">extends</span> <span class="title">PipelineOptions</span> </span>&#123;</div><div class="line">        <span class="meta">@Description</span>(<span class="string">"Sliding window duration, in seconds"</span>)</div><div class="line">        <span class="meta">@Default</span>.Long(WINDOW_SIZE)</div><div class="line">        <span class="function">Long <span class="title">getWindowSize</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setWindowSize</span><span class="params">(Long value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"Window slide, in seconds"</span>)</div><div class="line">        <span class="meta">@Default</span>.Long(SLIDE_SIZE)</div><div class="line">        <span class="function">Long <span class="title">getSlide</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setSlide</span><span class="params">(Long value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka topic to read from"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_TOPIC)</div><div class="line">        <span class="function">String <span class="title">getKafkaTopic</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setKafkaTopic</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka topic to write to"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_OUTPUT_TOPIC)</div><div class="line">        <span class="function">String <span class="title">getOutputKafkaTopic</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setOutputKafkaTopic</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Kafka Broker to read from"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(KAFKA_BROKER)</div><div class="line">        <span class="function">String <span class="title">getBroker</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setBroker</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The Zookeeper server to connect to"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(ZOOKEEPER)</div><div class="line">        <span class="function">String <span class="title">getZookeeper</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setZookeeper</span><span class="params">(String value)</span></span>;</div><div class="line"></div><div class="line">        <span class="meta">@Description</span>(<span class="string">"The groupId"</span>)</div><div class="line">        <span class="meta">@Default</span>.String(GROUP_ID)</div><div class="line">        <span class="function">String <span class="title">getGroup</span><span class="params">()</span></span>;</div><div class="line"></div><div class="line">        <span class="function"><span class="keyword">void</span> <span class="title">setGroup</span><span class="params">(String value)</span></span>;</div><div class="line">    &#125;</div><div class="line">        </div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        KafkaOptions options = PipelineOptionsFactory.fromArgs(args).withValidation().as(KafkaOptions.class);</div><div class="line">        options.setJobName(<span class="string">"KafkaExample - WindowSize: "</span> + options.getWindowSize() + <span class="string">" seconds"</span>);</div><div class="line"></div><div class="line">        Pipeline pipeline = Pipeline.create(options);</div><div class="line"></div><div class="line">        pipeline.apply(KafkaIO.&lt;Long, String&gt;read()</div><div class="line">                   .withBootstrapServers(<span class="string">"localhost:9092"</span>)</div><div class="line">                   .withTopic(KAFKA_TOPIC)  <span class="comment">// use withTopics(List&lt;String&gt;) to read from multiple topics.</span></div><div class="line">                   .withKeyDeserializer(LongDeserializer.class)</div><div class="line">                   .withValueDeserializer(StringDeserializer.class)</div><div class="line">                   .withoutMetadata() <span class="comment">// PCollection&lt;KV&lt;String, String&gt;&gt;</span></div><div class="line">        ).apply(KafkaIO.&lt;Long, String&gt;write()</div><div class="line">                    .withBootstrapServers(<span class="string">"localhost:9092"</span>)</div><div class="line">                    .withTopic(KAFKA_OUTPUT_TOPIC)</div><div class="line">                    .withKeySerializer(LongSerializer.class)</div><div class="line">                    .withValueSerializer(StringSerializer.class)</div><div class="line">                    <span class="comment">// you can further customize KafkaProducer used to write the records by adding more</span></div><div class="line">                    <span class="comment">// settings for ProducerConfig. e.g, to enable compression </span></div><div class="line">                    <span class="comment">//.updateProducerProperties(ImmutableMap.of("compression.type", "gzip"))</span></div><div class="line">        );</div><div class="line">                   </div><div class="line">        pipeline.run();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<div class="note danger"><p>这里注释掉的updateProducerProperties方法，可以用于设置kafka写入时所需的参数 </p>
</div>
<h2 id="运行任务"><a href="#运行任务" class="headerlink" title="运行任务"></a>运行任务</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mvn <span class="built_in">exec</span>:java -Dexec.mainClass=com.exmind.beam.App \</div><div class="line">    -Pflink-runner \</div><div class="line">    -Dexec.args=<span class="string">"--runner=FlinkRunner \</span></div><div class="line">      --flinkMaster=localhost:6123 \</div><div class="line">      --filesToStage=target/com.exmind.beam-0.0.1-SNAPSHOT.jar"</div></pre></td></tr></table></figure>
<p>使用-P指定runner，这里指定flink-runner作为运行器</p>
<h2 id="流程验证"><a href="#流程验证" class="headerlink" title="流程验证"></a>流程验证</h2><h3 id="flink运行状态检查"><a href="#flink运行状态检查" class="headerlink" title="flink运行状态检查"></a>flink运行状态检查</h3><p><img src="/images/beam-flink-sample.png" alt="img"></p>
<h3 id="kafka数据输入输出检查"><a href="#kafka数据输入输出检查" class="headerlink" title="kafka数据输入输出检查"></a>kafka数据输入输出检查</h3><p><img src="/images/beam-kafka-sample.png" alt="img"></p>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/sdks/javadoc/2.0.0/" target="_blank" rel="external">https://beam.apache.org/documentation/sdks/javadoc/2.0.0/</a><br><a href="https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java" target="_blank" rel="external">https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在网上看到这样一个例子&lt;br&gt;&lt;a href=&quot;https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java&lt;/a&gt;&lt;br&gt;但是从代码的设计上看对flink kafka存在依赖，而这样编写代码我觉得违背了apache beam的初衷，下面我自己写了一个很简单的例子，从kafka input-topic读取数据，写入kafka output-topic。&lt;br&gt;这里我只是做一个简单测试，所以使用的都是单机模式的kafka、zookeeper和flink&lt;/p&gt;
&lt;h2 id=&quot;公共参数&quot;&gt;&lt;a href=&quot;#公共参数&quot; class=&quot;headerlink&quot; title=&quot;公共参数&quot;&gt;&lt;/a&gt;公共参数&lt;/h2&gt;&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;long&lt;/span&gt; WINDOW_SIZE = &lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Default window duration in seconds&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;long&lt;/span&gt; SLIDE_SIZE = &lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Default window slide in seconds&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String KAFKA_TOPIC = &lt;span class=&quot;string&quot;&gt;&quot;input-topic&quot;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String KAFKA_OUTPUT_TOPIC = &lt;span class=&quot;string&quot;&gt;&quot;output-topic&quot;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String KAFKA_BROKER = &lt;span class=&quot;string&quot;&gt;&quot;localhost:9092&quot;&lt;/span&gt;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Default kafka broker to contact&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String GROUP_ID = &lt;span class=&quot;string&quot;&gt;&quot;beamGroup&quot;&lt;/span&gt;; &lt;span class=&quot;comment&quot;&gt;// Default groupId&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;static&lt;/span&gt; &lt;span class=&quot;keyword&quot;&gt;final&lt;/span&gt; String ZOOKEEPER = &lt;span class=&quot;string&quot;&gt;&quot;localhost:2181&quot;&lt;/span&gt;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam Runner - Flink</title>
    <link href="http://yoursite.com/2017/06/08/beam-2-0-0-runner-flink/"/>
    <id>http://yoursite.com/2017/06/08/beam-2-0-0-runner-flink/</id>
    <published>2017-06-08T08:12:25.000Z</published>
    <updated>2017-06-15T09:32:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用Flink-Runner先决条件及步骤"><a href="#使用Flink-Runner先决条件及步骤" class="headerlink" title="使用Flink Runner先决条件及步骤"></a>使用Flink Runner先决条件及步骤</h2><h3 id="检查apache-beam对应版本所需要的flink版本"><a href="#检查apache-beam对应版本所需要的flink版本" class="headerlink" title="检查apache beam对应版本所需要的flink版本"></a>检查apache beam对应版本所需要的flink版本</h3><p>方式一：(推荐)<br>github上查找beam项目，找到指定版本的flink runner的pom.xml文件，检查flink.version版本<br><a href="https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml" target="_blank" rel="external">https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml</a><br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">flink.version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">flink.version</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></div></pre></td></tr></table></figure></p>
<p>方式二：<br>官方所说的通过mvn命令查询支持的flink版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ mvn dependency:tree -Pflink-runner |grep flink</div><div class="line">...</div><div class="line">[INFO] |  +- org.apache.flink:flink-streaming-java_2.10:jar:1.1.2:runtime</div><div class="line">...</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h3 id="下载，安装flink"><a href="#下载，安装flink" class="headerlink" title="下载，安装flink"></a>下载，安装flink</h3><h4 id="下载链接："><a href="#下载链接：" class="headerlink" title="下载链接："></a>下载链接：</h4><p><a href="http://archive.apache.org/dist/flink/flink-1.2.1/flink-1.2.1-bin-hadoop24-scala_2.10.tgz" target="_blank" rel="external">flink-1.2.1-bin-hadoop24-scala_2.10.tgz</a></p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>flink安装可以参考官方的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/quickstart/setup_quickstart.html" target="_blank" rel="external">QuickStart</a>文档进行安装(测试只需要安装local模式)。</p>
<h2 id="引入maven依赖"><a href="#引入maven依赖" class="headerlink" title="引入maven依赖"></a>引入maven依赖</h2><p>使用java作为开发语言，需要在项目的pom.xml文件中加入此依赖<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.beam<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>beam-runners-flink_2.10<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">  <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div></pre></td></tr></table></figure></p>
<h2 id="使用flink-runner执行pipeline"><a href="#使用flink-runner执行pipeline" class="headerlink" title="使用flink runner执行pipeline"></a>使用flink runner执行pipeline</h2><p>apache beam使用flink runner通过-P指定<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ mvn package -Pflink-runner</div></pre></td></tr></table></figure></p>
<p>下面是官方给的一个例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ mvn <span class="built_in">exec</span>:java -Dexec.mainClass=org.apache.beam.examples.WordCount \</div><div class="line">    -Pflink-runner \</div><div class="line">    -Dexec.args=<span class="string">"--runner=FlinkRunner \</span></div><div class="line">      --inputFile=/path/to/pom.xml \</div><div class="line">      --output=/path/to/counts \</div><div class="line">      --flinkMaster=&lt;flink master url&gt; \</div><div class="line">      --filesToStage=target/word-count-beam--bundled-0.1.jar"</div></pre></td></tr></table></figure></p>
<p>注：<br>–flinkMaster:指定flink jobmanager访问地址，本地模式为localhost:6123;<br>–filesToStage:指定运行的jar包<br>以下两个参数为pipeline options提供给flink runner的内置参数，更多内置参数请点击<a href="https://beam.apache.org/documentation/runners/flink/" target="_blank" rel="external">这里</a>查阅   </p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><h3 id="依赖包"><a href="#依赖包" class="headerlink" title="依赖包"></a>依赖包</h3><p>将以下以来包放入flink lib目录下<br><div class="note info"><p> beam-runners-flink_2.10-2.0.0.jar<br>beam-sdks-java-core-2.0.0.jar<br>beam-sdks-java-io-kafka-2.0.0.jar<br>kafka-clients-0.10.1.0.jar<br>kafka_2.10-0.8.2.2.jar<br>beam-runners-core-java-2.0.0.jar<br>spring-core-4.3.6.RELEASE.jar<br>spring-expression-4.3.6.RELEASE.jar </p>
</div></p>
<h3 id="问题：apache-beam-2-0-0与apache-flink1-3-0版本问题"><a href="#问题：apache-beam-2-0-0与apache-flink1-3-0版本问题" class="headerlink" title="问题：apache beam 2.0.0与apache flink1.3.0版本问题"></a>问题：apache beam 2.0.0与apache flink1.3.0版本问题</h3><p>apache beam 2.0.0的runner flink是基于flink 1.2.1版本编译的，而flink1.3.0版本删除了JobSnapshottingSettings类，导致用flink1.3.0运行的时候抛ClassNotFoundException异常。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">java.lang.ClassNotFoundException: org.apache.flink.runtime.jobgraph.tasks.JobSnapshottingSettings</div><div class="line">    at java.net.URLClassLoader.findClass(URLClassLoader.java:<span class="number">381</span>)</div><div class="line">    at java.lang.ClassLoader.loadClass(ClassLoader.java:<span class="number">424</span>)</div><div class="line">    at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:<span class="number">331</span>)</div><div class="line">    ... (省略部分日志)</div></pre></td></tr></table></figure></p>
<p>解决方法：</p>
<ul>
<li>如果想使用最新的flink1.3.0，建议直接从github下载源码自行编译，目前apache beam的master分支已经是采用flink1.3.0版本。</li>
<li>采用flink1.2.1版本运行程序</li>
</ul>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/runners/flink/" target="_blank" rel="external">https://beam.apache.org/documentation/runners/flink/</a><br><a href="https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml" target="_blank" rel="external">https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用Flink-Runner先决条件及步骤&quot;&gt;&lt;a href=&quot;#使用Flink-Runner先决条件及步骤&quot; class=&quot;headerlink&quot; title=&quot;使用Flink Runner先决条件及步骤&quot;&gt;&lt;/a&gt;使用Flink Runner先决条件及步骤&lt;/h2&gt;&lt;h3 id=&quot;检查apache-beam对应版本所需要的flink版本&quot;&gt;&lt;a href=&quot;#检查apache-beam对应版本所需要的flink版本&quot; class=&quot;headerlink&quot; title=&quot;检查apache beam对应版本所需要的flink版本&quot;&gt;&lt;/a&gt;检查apache beam对应版本所需要的flink版本&lt;/h3&gt;&lt;p&gt;方式一：(推荐)&lt;br&gt;github上查找beam项目，找到指定版本的flink runner的pom.xml文件，检查flink.version版本&lt;br&gt;&lt;a href=&quot;https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml&lt;/a&gt;&lt;br&gt;&lt;figure class=&quot;highlight xml&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &lt;span class=&quot;tag&quot;&gt;&amp;lt;&lt;span class=&quot;name&quot;&gt;flink.version&lt;/span&gt;&amp;gt;&lt;/span&gt;1.2.1&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;flink.version&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&lt;span class=&quot;tag&quot;&gt;&amp;lt;/&lt;span class=&quot;name&quot;&gt;properties&lt;/span&gt;&amp;gt;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;方式二：&lt;br&gt;官方所说的通过mvn命令查询支持的flink版本&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ mvn dependency:tree -Pflink-runner |grep flink&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;...&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[INFO] |  +- org.apache.flink:flink-streaming-java_2.10:jar:1.1.2:runtime&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;...&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
      <category term="apache flink" scheme="http://yoursite.com/tags/apache-flink/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam:便携式并行数据处理</title>
    <link href="http://yoursite.com/2017/06/02/apache-beam-protable-and-parallel-data-processing/"/>
    <id>http://yoursite.com/2017/06/02/apache-beam-protable-and-parallel-data-processing/</id>
    <published>2017-06-02T08:24:47.000Z</published>
    <updated>2017-06-15T09:31:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Apache-Beam-Portable-and-Parallel-Data-Processing"><a href="#Apache-Beam-Portable-and-Parallel-Data-Processing" class="headerlink" title="Apache Beam: Portable and Parallel Data Processing"></a>Apache Beam: Portable and Parallel Data Processing</h2><iframe width="560" height="315" src="https://www.youtube.com/embed/owTuuVt6Oro" frameborder="0" allowfullscreen></iframe>

<h2 id="概念说明"><a href="#概念说明" class="headerlink" title="概念说明"></a>概念说明</h2><p>在我们做数据流处理的过程中，经常会遇到的一个问题：网络延迟。当然对于无序的数据流来说，网络延迟所带来的数据乱序对结果是不会有太大影响的。但是对于数据顺序有要求的应用，则会导致数据不一致等棘手的问题。<br><a id="more"></a><br>官方给出的一个例子中，包含两个维度：</p>
<ul>
<li>事件事件(Event Time):  事件发生时间</li>
<li>处理事件(Processing Time):事件处理时间<br><img src="/images/beam-processingTime-eventTime.png" alt="img"><br>上图中，横轴代表事件发生时间，纵轴代表事件处理事件。在做数据处理的时候，我们往往所理想的情况是数据一出来就被处理完成，图中虚线则代表了这种理想情况。<br>注：离虚线越近的事件延迟低(图中突出的3事件)，反之则延迟高(图中突出的9事件)</li>
</ul>
<h2 id="Beam模型围绕的四个关键问题"><a href="#Beam模型围绕的四个关键问题" class="headerlink" title="Beam模型围绕的四个关键问题"></a>Beam模型围绕的四个关键问题</h2><h3 id="计算的结果是什么？（What-results-are-calculated-）"><a href="#计算的结果是什么？（What-results-are-calculated-）" class="headerlink" title="计算的结果是什么？（What results are calculated?）"></a>计算的结果是什么？（What results are calculated?）</h3><p>例如，Sum、Join或是机器学习中训练学习模型等。在Beam SDK中由Pipeline中的操作符指定。<br>下图展示一个sum示例，累计12:00-12:10分的数字累加。<br><img src="/images/beam-what.jpg" alt="img"><br>对应Beam代码如下：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>通过input.apply()方法，通过beam提供的transforms的Sum进行数据统计<br><img src="/images/what-is-being-computed.png" alt="img"></p>
<h3 id="数据在什么范围中计算？-Where-in-event-time-are-result-calculated"><a href="#数据在什么范围中计算？-Where-in-event-time-are-result-calculated" class="headerlink" title="数据在什么范围中计算？(Where in event time are result calculated?)"></a>数据在什么范围中计算？(Where in event time are result calculated?)</h3><p>例如，基于Process-Time的时间窗口，基于Event-Time的时间窗口、滑动窗口等。在BeamSDK中由Pipeline中的窗口指定<br>假如我们现在想在事件时间横轴上统计每个2分钟时间窗口的整数累加值，即完成如下图动画所示的效果<br><img src="/images/beam-where.jpg" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(<span class="number">2</span>))))</div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>Beam 自动为每个时间窗口创建一个小的批处理作业，在处理时间纵轴 12:10 的时候触发计算。但是这样，我们只能等到最后的一个时间点（12:10）才能得到计算结果。</p>
<p>所支持的窗口列表如下：<br><img src="/images/where-in-event-time.png" alt="img"></p>
<h3 id="何时将结果数据落地？-When-in-processing-time-are-results-materialized"><a href="#何时将结果数据落地？-When-in-processing-time-are-results-materialized" class="headerlink" title="何时将结果数据落地？(When in processing time are results materialized?)"></a>何时将结果数据落地？(When in processing time are results materialized?)</h3><p>例如，在1小时的Event-Time时间窗口中，每隔2分钟，将当前窗口计算结果输出。</p>
<p>在上个问题中，我们以2分钟为间隔，输出每2分钟的统计结果。但是如果用户想提前将结果写入统计结果，那么我们就要对代码做一定的修改。<br><img src="/images/beam-when.jpg" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(<span class="number">2</span>)))</div><div class="line">            .triggering(AtWatermark()))            </div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>此处引入了触发器(Trigger)以及水平线(Watermark)，触发器(Trigger)决定何时将计算结果发射出去，发射太早会丢失一部分数据，丧失精确性，发射太晚会导致延迟变长，而且会囤积大量数据，何时触发器(Trigger)是由水位线(Watermark)来决定的，在Beam SDK中由Pipeline中的水位线和触发器指定</p>
<p>所支持的触发器(Trigger)列表如下：<br><img src="/images/when-in-processing-time.png" alt="img"></p>
<h3 id="如何对结果进行改进修正？-How-do-refinements-of-results-relate"><a href="#如何对结果进行改进修正？-How-do-refinements-of-results-relate" class="headerlink" title="如何对结果进行改进修正？(How do refinements of results relate?)"></a>如何对结果进行改进修正？(How do refinements of results relate?)</h3><p>例如，将迟到数据计算增量结果输出，或是将迟到数据计算结果和窗口内数据计算结果合并成全量结果输出。在Beam SDK中由Accumulation指定</p>
<p>从上个问题的动图中可以看出，虽然我们解决了提前写入事件窗口的统计结果提前写入的问题，但是从动图上可以看出，结果统计遗漏了9这个事件，接下来这步我们就要解决这个问题。<br><img src="/images/beam-how.jpg" alt="img"><br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(<span class="number">2</span>)))</div><div class="line">           .triggering(AtWatermark()</div><div class="line">              .withEarlyFirings(AtPeriod(Duration.standardMinutes(<span class="number">1</span>)))</div><div class="line">              .withLateFirings(AtCount(<span class="number">1</span>)))</div><div class="line">           .accumulatingFiredPanes())            </div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>所支持的改进修正功能列表如下：<br><img src="/images/How-do-refinements-relate.png" alt="img"></p>
<p>参考连接：<br><a href="https://beam.apache.org/documentation/runners/capability-matrix/#cap-summary-what" target="_blank" rel="external">https://beam.apache.org/documentation/runners/capability-matrix/#cap-summary-what</a><br><a href="http://www.jianshu.com/p/357bf071d017" target="_blank" rel="external">http://www.jianshu.com/p/357bf071d017</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Apache-Beam-Portable-and-Parallel-Data-Processing&quot;&gt;&lt;a href=&quot;#Apache-Beam-Portable-and-Parallel-Data-Processing&quot; class=&quot;headerlink&quot; title=&quot;Apache Beam: Portable and Parallel Data Processing&quot;&gt;&lt;/a&gt;Apache Beam: Portable and Parallel Data Processing&lt;/h2&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/owTuuVt6Oro&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;概念说明&quot;&gt;&lt;a href=&quot;#概念说明&quot; class=&quot;headerlink&quot; title=&quot;概念说明&quot;&gt;&lt;/a&gt;概念说明&lt;/h2&gt;&lt;p&gt;在我们做数据流处理的过程中，经常会遇到的一个问题：网络延迟。当然对于无序的数据流来说，网络延迟所带来的数据乱序对结果是不会有太大影响的。但是对于数据顺序有要求的应用，则会导致数据不一致等棘手的问题。&lt;br&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam 介绍</title>
    <link href="http://yoursite.com/2017/06/02/apache-beam-introduce/"/>
    <id>http://yoursite.com/2017/06/02/apache-beam-introduce/</id>
    <published>2017-06-02T08:23:12.000Z</published>
    <updated>2017-06-02T08:27:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>作为一名大数据开发者，不得不说自从hadoop问世之后，接连而来的各种各样的大数据处理框架层出不穷，而我们则要不断的去学习，运用不同的技术、框架、api，甚至是开发语言以及sdk，去开发项目功能，解决项目问题。</p>
<ul>
<li>平台迁移问题：根据项目的需求，技术的更新迭代，项目性能的要求等等，同样的业务要在不同的框架上运行，可能你就要花费很长一段时间去学习新的框架，新的api。</li>
<li>开发工具难抉择：近两年开启的开源大潮，为大数据开发者提供了十分富余的工具。但这同时也增加了开发者选择合适的工具的难度，尤其对于新入行的开发者来说。这很可能拖慢、甚至阻碍开源工具的发展<a id="more"></a>
Apache Beam（原名Google DataFlow）是Google在2016年2月份贡献给Apache基金会的Apache孵化项目，被认为是继MapReduce，GFS和BigQuery等之后，Google在大数据处理领域对开源社区的又一个非常大的贡献。Apache Beam的主要目标是统一批处理和流处理的编程范式，为无限，乱序，web-scale的数据集处理提供简单灵活，功能丰富以及表达能力十分强大的SDK。<br>Apache Beam项目重点在于数据处理的编程范式和接口定义，并不涉及具体执行引擎的实现。<br>Apache Beam希望基于Beam开发的数据处理程序可以执行在任意的分布式计算引擎上<br><img src="/images/bigdata.png" alt="img"></li>
</ul>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul>
<li>统一(Unified)：<br> 对于批处理和流式处理，使用单一的编程模型，能够实现批处理（Batch processing）、流处理（Streaming Processing），通常的做法是把待处理的数据集（Dataset）统一，一般会把有界（Bound）数据集作为无界（Unbound）数据集的一种特殊情况来看待，比如Apache Flink便是按照这种方式处理，在差异化的API层之上构建一个统一的API层。</li>
<li>可移植(Portable)：<br> 在多个不同的计算环境下，都能够执行已经定义好的数据处理Pipeline。也就是说，对数据集处理的定义（即构建的Data Pipeline），与最终所要Deploy的执行环境完全无关。这对实现数据处理的企业是非常友好的，当下数据处理新技术不断涌现，企业数据处理平台也为了能够与时俱进并提高处理效率，当然希望在底层计算平台升级的过程中无需重写上层已定义的Data Pipeline。<br> 目前，Apache Beam项目开发整体来看还处在初期，初步决定底层执行环境支持主流的计算平台：<br> Apache Apex、Apache Flink、Apache Spark、Google Cloud Dataflow。实际上，Apache Beam的这种统一编程模型，可以支持任意的计算引擎，通过Data Pipeline层与执行引擎层之间开发一个类似Driver的连接器即可实现。</li>
<li>可拓展(Extensible)：可以实现和分享更多的新SDK、IO连接器、转换操作库等；</li>
</ul>
<!-- more -->
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>管道，包装数据处理流程任务</p>
<h3 id="PCollection"><a href="#PCollection" class="headerlink" title="PCollection"></a>PCollection</h3><p>分布式数据集，PCollection是管道中每个步骤的输入、输出</p>
<h3 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h3><p>管道中的每个步骤，它接收一个或者若干个输入PCollection，进行处理后，输出PCollection</p>
<h3 id="I-O-sources-and-sinks"><a href="#I-O-sources-and-sinks" class="headerlink" title="I/O sources and sinks"></a>I/O sources and sinks</h3><p>source和sink用于提供数据的输入和输出端点<br>目前支持如下：</p>
<h4 id="内嵌-I-O-转换"><a href="#内嵌-I-O-转换" class="headerlink" title="内嵌 I/O 转换"></a>内嵌 I/O 转换</h4><table>
<thead>
<tr>
<th>Language</th>
<th>File-based</th>
<th>Messaging</th>
<th>Database</th>
</tr>
</thead>
<tbody>
<tr>
<td>Java</td>
<td>AvroIO<br>Apache Hadoop File System<br>TextIO<br>XML</td>
<td>JMS<br>Apache Kafka<br>Amazon Kinesis<br>Google Cloud PubSub</td>
<td>Apache Hadoop InputFormat<br>Apache HBase<br>MongoDB<br>JDBC<br>Google BigQuery<br>Google Cloud Bigtable<br>Google Cloud Datastore</td>
</tr>
<tr>
<td>Python</td>
<td>avroio<br>textio</td>
<td></td>
<td>Google BigQuery<br>Google Cloud Datastore</td>
</tr>
</tbody>
</table>
<h4 id="拓展-I-O-转换"><a href="#拓展-I-O-转换" class="headerlink" title="拓展 I/O 转换"></a>拓展 I/O 转换</h4><table>
<thead>
<tr>
<th>Name</th>
<th>Language</th>
<th>JIRA</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMQP</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1237" target="_blank" rel="external">BEAM-1237</a></td>
</tr>
<tr>
<td>Apache Cassandra</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-245" target="_blank" rel="external">BEAM-245</a></td>
</tr>
<tr>
<td>Apache DistributedLog</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-607" target="_blank" rel="external">BEAM-607</a></td>
</tr>
<tr>
<td>Apache Hive</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1158" target="_blank" rel="external">BEAM-1158</a></td>
</tr>
<tr>
<td>Apache Parquet</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-214" target="_blank" rel="external">BEAM-214</a></td>
</tr>
<tr>
<td>Apache Solr</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1236" target="_blank" rel="external">BEAM-1236</a></td>
</tr>
<tr>
<td>Apache Sqoop</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-67" target="_blank" rel="external">BEAM-67</a></td>
</tr>
<tr>
<td>Couchbase</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1893" target="_blank" rel="external">BEAM-1893</a></td>
</tr>
<tr>
<td>JSON</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1581" target="_blank" rel="external">BEAM-1581</a></td>
</tr>
<tr>
<td>Memcached</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1678" target="_blank" rel="external">BEAM-1678</a></td>
</tr>
<tr>
<td>Neo4j</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1857" target="_blank" rel="external">BEAM-1857</a></td>
</tr>
<tr>
<td>Redis</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1017" target="_blank" rel="external">BEAM-1017</a></td>
</tr>
<tr>
<td>RabbitMQ</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1240" target="_blank" rel="external">BEAM-1240</a></td>
</tr>
<tr>
<td>RestIO</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1946" target="_blank" rel="external">BEAM-1946</a></td>
</tr>
<tr>
<td>TikaIO</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-2328" target="_blank" rel="external">BEAM-2328</a></td>
</tr>
<tr>
<td>Cloud Spanner</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1542" target="_blank" rel="external">BEAM-1542</a></td>
</tr>
</tbody>
</table>
<h2 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h2><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="/images/apache-beam-framework.png" alt="img"><br>通过上图，我们可以清楚的知道，执行一个流程分以下步骤：</p>
<ul>
<li>End Users：选择一种你熟悉的编程语言提交应用</li>
<li>SDK Writers：该编程语言必须是 Beam 模型支持的</li>
<li>Library Writers：转换成Beam模型的格式</li>
<li>Runner Writers：在分布式环境下处理并支持Beam的数据处理管道</li>
<li>IO Providers：在Beam的数据处理管道上运行所有的应用</li>
<li>DSL Writers：创建一个高阶的数据处理管道<h3 id="Beam核心组成部分"><a href="#Beam核心组成部分" class="headerlink" title="Beam核心组成部分"></a>Beam核心组成部分</h3></li>
<li>Beam SDK<br> Beam SDK提供一个统一的编程接口给到上层应用的开发者，开发者不需要了解底层的具体的大数据平台的开发接口是什么，直接通过Beam SDK的接口，就可以开发数据处理的加工流程，不管输入是用于批处理的有限数据集，还是流式的无限数据集。对于有限或无限的输入数据，Beam SDK都使用相同的类来表现，并且使用相同的转换操作进行处理。Beam SDK可以有不同编程语言的实现，目前已经完整地提供了Java，python的SDK还在开发过程中，相信未来会有更多不同的语言的SDK会发布出来。</li>
<li>Beam Pipeline Runner<br> Beam Pipeline Runner将用户用Beam模型定义开发的处理流程翻译成底层的分布式数据处理平台支持的运行时环境。在运行Beam程序时，需要指明底层的正确Runner类型。针对不同的大数据平台，会有不同的Runner。目前Flink、Spark、Apex以及谷歌的Cloud DataFlow都有支持Beam的Runner。</li>
</ul>
<h3 id="语言-Language"><a href="#语言-Language" class="headerlink" title="语言(Language)"></a>语言(Language)</h3><p><img src="/images/beam_architecture.png" alt="img"></p>
<h3 id="运行器-Runner"><a href="#运行器-Runner" class="headerlink" title="运行器(Runner)"></a>运行器(Runner)</h3><p><img src="/images/beam-workers.jpg" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Apache Beam的Beam Model对无限乱序数据流的数据处理进行了非常优雅的抽象，“WWWH”四个维度对数据处理的描述，非常清晰与合理，Beam Model在统一了对无限数据流和有限数据集的处理模式的同时，也明确了对无限数据流的数据处理方式的编程范式，扩大了流处理系统可应用的业务范围，例如，Event-Time/Session窗口的支持，乱序数据的处理支持等。Apache Flink，Apache Spark Streaming等项目的API设计均越来越多的借鉴或参考了Apache Beam Model，且作为Beam Runner的实现，与Beam SDK的兼容度也越来越高。<br>目前apache beam的开发处于初步阶段，对python的支持还在开发中，对java的支持的内容相对比较丰富，支持的runner也会逐步增加，实现平台迁移的可移植，降低／解决大数据开发者框架选择的问题。</p>
<p>参考链接：<br><a href="https://www.infoq.com/presentations/apache-beam" target="_blank" rel="external">https://www.infoq.com/presentations/apache-beam</a><br><a href="https://beam.apache.org/documentation/io/built-in/" target="_blank" rel="external">https://beam.apache.org/documentation/io/built-in/</a><br><a href="http://www.cnblogs.com/smartloli/p/6685106.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/6685106.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;作为一名大数据开发者，不得不说自从hadoop问世之后，接连而来的各种各样的大数据处理框架层出不穷，而我们则要不断的去学习，运用不同的技术、框架、api，甚至是开发语言以及sdk，去开发项目功能，解决项目问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平台迁移问题：根据项目的需求，技术的更新迭代，项目性能的要求等等，同样的业务要在不同的框架上运行，可能你就要花费很长一段时间去学习新的框架，新的api。&lt;/li&gt;
&lt;li&gt;开发工具难抉择：近两年开启的开源大潮，为大数据开发者提供了十分富余的工具。但这同时也增加了开发者选择合适的工具的难度，尤其对于新入行的开发者来说。这很可能拖慢、甚至阻碍开源工具的发展
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>常用工具库</title>
    <link href="http://yoursite.com/2017/05/31/common-tools-repository/"/>
    <id>http://yoursite.com/2017/05/31/common-tools-repository/</id>
    <published>2017-05-31T15:05:05.000Z</published>
    <updated>2017-06-15T09:32:42.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Maven-Search-Repository"><a href="#Maven-Search-Repository" class="headerlink" title="Maven Search Repository"></a>Maven Search Repository</h2><p>一直以来都是以maven来开发项目，这里提供两个maven查询库地址。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ http://search.maven.org</div></pre></td></tr></table></figure></p>
<p>More info: <a href="http://search.maven.org" target="_blank" rel="external">Link</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ http://mvnrepository.com</div></pre></td></tr></table></figure></p>
<p>More info: <a href="http://mvnrepository.com" target="_blank" rel="external">Link</a><br><a id="more"></a></p>
<h2 id="Jsoup-Tool"><a href="#Jsoup-Tool" class="headerlink" title="Jsoup Tool"></a>Jsoup Tool</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ https://try.jsoup.org</div></pre></td></tr></table></figure>
<p>More info: <a href="https://try.jsoup.org" target="_blank" rel="external">Link</a></p>
<h2 id="Ali-Maven-Source-Repository"><a href="#Ali-Maven-Source-Repository" class="headerlink" title="Ali Maven Source Repository"></a>Ali Maven Source Repository</h2><p>maven官网提供的repository下载速度过慢，影响工作效率，这里提供一个ali maven repository给大家使用.<br><a href="/files/settings.xml">ali maven settings file</a><br>如需要修改repository的存放位置，可以修改以下配置<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ <span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>$&#123;user.home&#125;/.m2/repository<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Maven-Search-Repository&quot;&gt;&lt;a href=&quot;#Maven-Search-Repository&quot; class=&quot;headerlink&quot; title=&quot;Maven Search Repository&quot;&gt;&lt;/a&gt;Maven Search Repository&lt;/h2&gt;&lt;p&gt;一直以来都是以maven来开发项目，这里提供两个maven查询库地址。&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ http://search.maven.org&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a href=&quot;http://search.maven.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Link&lt;/a&gt;&lt;br&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ http://mvnrepository.com&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a href=&quot;http://mvnrepository.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Link&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="tools" scheme="http://yoursite.com/categories/tools/"/>
    
    
      <category term="maven" scheme="http://yoursite.com/tags/maven/"/>
    
      <category term="jsoup" scheme="http://yoursite.com/tags/jsoup/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/05/02/hello-world/"/>
    <id>http://yoursite.com/2017/05/02/hello-world/</id>
    <published>2017-05-02T08:23:12.000Z</published>
    <updated>2017-06-02T08:43:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a><br><a id="more"></a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Writing&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Testing" scheme="http://yoursite.com/categories/Testing/"/>
    
    
      <category term="Hello" scheme="http://yoursite.com/tags/Hello/"/>
    
  </entry>
  
</feed>
