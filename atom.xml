<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jonathan.Wei&#39;s Notes</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2017-06-15T07:20:16.000Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Jonathan.Wei</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Apache Beam IO - KafkaIO</title>
    <link href="http://yoursite.com/2017/06/09/apache-beam-kafka-io-sample/"/>
    <id>http://yoursite.com/2017/06/09/apache-beam-kafka-io-sample/</id>
    <published>2017-06-09T02:20:48.000Z</published>
    <updated>2017-06-15T07:20:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>之前在网上看到这样一个例子<br><a href="https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java" target="_blank" rel="external">https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java</a><br>但是从代码的设计上看对flink kafka存在依赖，而这样编写代码我觉得违背了apache beam的初衷，下面我自己写了一个很简单的例子，从kafka input-topic读取数据，写入kafka output-topic。<br>这里我只是做一个简单测试，所以使用的都是单机模式的kafka、zookeeper和flink</p>
<h2 id="公共参数"><a href="#公共参数" class="headerlink" title="公共参数"></a>公共参数</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">private static final long WINDOW_SIZE = 10;</div><div class="line">// Default window duration in seconds</div><div class="line">private static final long SLIDE_SIZE = 5;</div><div class="line">// Default window slide in seconds</div><div class="line">private static final String KAFKA_TOPIC = &quot;input-topic&quot;;</div><div class="line">private static final String KAFKA_OUTPUT_TOPIC = &quot;output-topic&quot;;</div><div class="line">private static final String KAFKA_BROKER = &quot;localhost:9092&quot;;</div><div class="line">// Default kafka broker to contact</div><div class="line">private static final String GROUP_ID = &quot;beamGroup&quot;; // Default groupId</div><div class="line">private static final String ZOOKEEPER = &quot;localhost:2181&quot;;</div></pre></td></tr></table></figure>
<a id="more"></a>
<h2 id="创建option"><a href="#创建option" class="headerlink" title="创建option"></a>创建option</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line">public interface KafkaOptions extends PipelineOptions &#123;</div><div class="line">        @Description(&quot;Sliding window duration, in seconds&quot;)</div><div class="line">        @Default.Long(WINDOW_SIZE)</div><div class="line">        Long getWindowSize();</div><div class="line"></div><div class="line">        void setWindowSize(Long value);</div><div class="line"></div><div class="line">        @Description(&quot;Window slide, in seconds&quot;)</div><div class="line">        @Default.Long(SLIDE_SIZE)</div><div class="line">        Long getSlide();</div><div class="line"></div><div class="line">        void setSlide(Long value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka topic to read from&quot;)</div><div class="line">        @Default.String(KAFKA_TOPIC)</div><div class="line">        String getKafkaTopic();</div><div class="line"></div><div class="line">        void setKafkaTopic(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka topic to write to&quot;)</div><div class="line">        @Default.String(KAFKA_OUTPUT_TOPIC)</div><div class="line">        String getOutputKafkaTopic();</div><div class="line"></div><div class="line">        void setOutputKafkaTopic(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka Broker to read from&quot;)</div><div class="line">        @Default.String(KAFKA_BROKER)</div><div class="line">        String getBroker();</div><div class="line"></div><div class="line">        void setBroker(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Zookeeper server to connect to&quot;)</div><div class="line">        @Default.String(ZOOKEEPER)</div><div class="line">        String getZookeeper();</div><div class="line"></div><div class="line">        void setZookeeper(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The groupId&quot;)</div><div class="line">        @Default.String(GROUP_ID)</div><div class="line">        String getGroup();</div><div class="line"></div><div class="line">        void setGroup(String value);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<h2 id="KafkaIO-Read"><a href="#KafkaIO-Read" class="headerlink" title="KafkaIO Read"></a>KafkaIO Read</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">KafkaIO.&lt;Long, String&gt;read()</div><div class="line">                   .withBootstrapServers(&quot;localhost:9092&quot;)</div><div class="line">                   .withTopic(KAFKA_TOPIC)  // use withTopics(List&lt;String&gt;) to read from multiple topics.</div><div class="line">                   .withKeyDeserializer(LongDeserializer.class)</div><div class="line">                   .withValueDeserializer(StringDeserializer.class)</div><div class="line">                   .withoutMetadata() // PCollection&lt;KV&lt;String, String&gt;&gt;</div></pre></td></tr></table></figure>
<h2 id="KafkaIO-Write"><a href="#KafkaIO-Write" class="headerlink" title="KafkaIO Write"></a>KafkaIO Write</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">KafkaIO.&lt;Long, String&gt;write()</div><div class="line">                    .withBootstrapServers(&quot;localhost:9092&quot;)</div><div class="line">                    .withTopic(KAFKA_OUTPUT_TOPIC)</div><div class="line">                    .withKeySerializer(LongSerializer.class)</div><div class="line">                    .withValueSerializer(StringSerializer.class)</div><div class="line">                    // you can further customize KafkaProducer used to write the records by adding more</div><div class="line">                    // settings for ProducerConfig. e.g, to enable compression :</div><div class="line">                    //.updateProducerProperties(ImmutableMap.of(&quot;compression.type&quot;, &quot;gzip&quot;))</div></pre></td></tr></table></figure>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码"></a>完整代码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div></pre></td><td class="code"><pre><div class="line">package com.exmind.beam;</div><div class="line"></div><div class="line">import org.apache.beam.sdk.Pipeline;</div><div class="line">import org.apache.beam.sdk.io.kafka.KafkaIO;</div><div class="line">import org.apache.beam.sdk.options.Default;</div><div class="line">import org.apache.beam.sdk.options.Description;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptions;</div><div class="line">import org.apache.beam.sdk.options.PipelineOptionsFactory;</div><div class="line">import org.apache.kafka.common.serialization.LongDeserializer;</div><div class="line">import org.apache.kafka.common.serialization.LongSerializer;</div><div class="line">import org.apache.kafka.common.serialization.StringDeserializer;</div><div class="line">import org.apache.kafka.common.serialization.StringSerializer;</div><div class="line"></div><div class="line">public class App &#123;</div><div class="line"></div><div class="line">    private static final long WINDOW_SIZE = 10;</div><div class="line">    // Default window duration in seconds</div><div class="line">    private static final long SLIDE_SIZE = 5;</div><div class="line">    // Default window slide in seconds</div><div class="line">    private static final String KAFKA_TOPIC = &quot;input-topic&quot;;</div><div class="line">    private static final String KAFKA_OUTPUT_TOPIC = &quot;output-topic&quot;;</div><div class="line">    private static final String KAFKA_BROKER = &quot;localhost:9092&quot;;</div><div class="line">    // Default kafka broker to contact</div><div class="line">    private static final String GROUP_ID = &quot;beamGroup&quot;; // Default groupId</div><div class="line">    private static final String ZOOKEEPER = &quot;localhost:2181&quot;;</div><div class="line"></div><div class="line">    public interface KafkaOptions extends PipelineOptions &#123;</div><div class="line">        @Description(&quot;Sliding window duration, in seconds&quot;)</div><div class="line">        @Default.Long(WINDOW_SIZE)</div><div class="line">        Long getWindowSize();</div><div class="line"></div><div class="line">        void setWindowSize(Long value);</div><div class="line"></div><div class="line">        @Description(&quot;Window slide, in seconds&quot;)</div><div class="line">        @Default.Long(SLIDE_SIZE)</div><div class="line">        Long getSlide();</div><div class="line"></div><div class="line">        void setSlide(Long value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka topic to read from&quot;)</div><div class="line">        @Default.String(KAFKA_TOPIC)</div><div class="line">        String getKafkaTopic();</div><div class="line"></div><div class="line">        void setKafkaTopic(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka topic to write to&quot;)</div><div class="line">        @Default.String(KAFKA_OUTPUT_TOPIC)</div><div class="line">        String getOutputKafkaTopic();</div><div class="line"></div><div class="line">        void setOutputKafkaTopic(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Kafka Broker to read from&quot;)</div><div class="line">        @Default.String(KAFKA_BROKER)</div><div class="line">        String getBroker();</div><div class="line"></div><div class="line">        void setBroker(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The Zookeeper server to connect to&quot;)</div><div class="line">        @Default.String(ZOOKEEPER)</div><div class="line">        String getZookeeper();</div><div class="line"></div><div class="line">        void setZookeeper(String value);</div><div class="line"></div><div class="line">        @Description(&quot;The groupId&quot;)</div><div class="line">        @Default.String(GROUP_ID)</div><div class="line">        String getGroup();</div><div class="line"></div><div class="line">        void setGroup(String value);</div><div class="line">    &#125;</div><div class="line">        </div><div class="line">    public static void main(String[] args) &#123;</div><div class="line">        KafkaOptions options = PipelineOptionsFactory.fromArgs(args).withValidation().as(KafkaOptions.class);</div><div class="line">        options.setJobName(&quot;KafkaExample - WindowSize: &quot; + options.getWindowSize() + &quot; seconds&quot;);</div><div class="line"></div><div class="line">        Pipeline pipeline = Pipeline.create(options);</div><div class="line"></div><div class="line">        pipeline.apply(KafkaIO.&lt;Long, String&gt;read()</div><div class="line">                   .withBootstrapServers(&quot;localhost:9092&quot;)</div><div class="line">                   .withTopic(KAFKA_TOPIC)  // use withTopics(List&lt;String&gt;) to read from multiple topics.</div><div class="line">                   .withKeyDeserializer(LongDeserializer.class)</div><div class="line">                   .withValueDeserializer(StringDeserializer.class)</div><div class="line">                   .withoutMetadata() // PCollection&lt;KV&lt;String, String&gt;&gt;</div><div class="line">        ).apply(KafkaIO.&lt;Long, String&gt;write()</div><div class="line">                    .withBootstrapServers(&quot;localhost:9092&quot;)</div><div class="line">                    .withTopic(KAFKA_OUTPUT_TOPIC)</div><div class="line">                    .withKeySerializer(LongSerializer.class)</div><div class="line">                    .withValueSerializer(StringSerializer.class)</div><div class="line">                    // you can further customize KafkaProducer used to write the records by adding more</div><div class="line">                    // settings for ProducerConfig. e.g, to enable compression </div><div class="line">                    //.updateProducerProperties(ImmutableMap.of(&quot;compression.type&quot;, &quot;gzip&quot;))</div><div class="line">        );</div><div class="line">                   </div><div class="line">        pipeline.run();</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<div class="note danger"><p>这里注释掉的updateProducerProperties方法，可以用于设置kafka写入时所需的参数 </p>
</div>
<h2 id="运行任务"><a href="#运行任务" class="headerlink" title="运行任务"></a>运行任务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">mvn exec:java -Dexec.mainClass=com.exmind.beam.App \</div><div class="line">    -Pflink-runner \</div><div class="line">    -Dexec.args=&quot;--runner=FlinkRunner \</div><div class="line">      --flinkMaster=localhost:6123 \</div><div class="line">      --filesToStage=target/com.exmind.beam-0.0.1-SNAPSHOT.jar&quot;</div></pre></td></tr></table></figure>
<p>使用-P指定runner，这里指定flink-runner作为运行器</p>
<h2 id="流程验证"><a href="#流程验证" class="headerlink" title="流程验证"></a>流程验证</h2><h3 id="flink运行状态检查"><a href="#flink运行状态检查" class="headerlink" title="flink运行状态检查"></a>flink运行状态检查</h3><p><img src="/images/beam-flink-sample.png" alt="img"></p>
<h3 id="kafka数据输入输出检查"><a href="#kafka数据输入输出检查" class="headerlink" title="kafka数据输入输出检查"></a>kafka数据输入输出检查</h3><p><img src="/images/beam-kafka-sample.png" alt="img"></p>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/sdks/javadoc/2.0.0/" target="_blank" rel="external">https://beam.apache.org/documentation/sdks/javadoc/2.0.0/</a><br><a href="https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java" target="_blank" rel="external">https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/test/java/org/apache/beam/sdk/io/kafka/KafkaIOTest.java</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前在网上看到这样一个例子&lt;br&gt;&lt;a href=&quot;https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/wtanaka/streaming/blob/d2e63184f604ea42d9711dd59951af3f3f4200f9/beam/src/main/java/com/wtanaka/streaming/beam/KafkaToKafka.java&lt;/a&gt;&lt;br&gt;但是从代码的设计上看对flink kafka存在依赖，而这样编写代码我觉得违背了apache beam的初衷，下面我自己写了一个很简单的例子，从kafka input-topic读取数据，写入kafka output-topic。&lt;br&gt;这里我只是做一个简单测试，所以使用的都是单机模式的kafka、zookeeper和flink&lt;/p&gt;
&lt;h2 id=&quot;公共参数&quot;&gt;&lt;a href=&quot;#公共参数&quot; class=&quot;headerlink&quot; title=&quot;公共参数&quot;&gt;&lt;/a&gt;公共参数&lt;/h2&gt;&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;5&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;6&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;7&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;8&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;9&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;10&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;private static final long WINDOW_SIZE = 10;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;// Default window duration in seconds&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final long SLIDE_SIZE = 5;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;// Default window slide in seconds&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final String KAFKA_TOPIC = &amp;quot;input-topic&amp;quot;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final String KAFKA_OUTPUT_TOPIC = &amp;quot;output-topic&amp;quot;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final String KAFKA_BROKER = &amp;quot;localhost:9092&amp;quot;;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;// Default kafka broker to contact&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final String GROUP_ID = &amp;quot;beamGroup&amp;quot;; // Default groupId&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;private static final String ZOOKEEPER = &amp;quot;localhost:2181&amp;quot;;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
      <category term="kafka" scheme="http://yoursite.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam Runner - Flink</title>
    <link href="http://yoursite.com/2017/06/08/beam-2-0-0-runner-flink/"/>
    <id>http://yoursite.com/2017/06/08/beam-2-0-0-runner-flink/</id>
    <published>2017-06-08T08:12:25.000Z</published>
    <updated>2017-06-15T03:50:11.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="使用Flink-Runner先决条件及步骤"><a href="#使用Flink-Runner先决条件及步骤" class="headerlink" title="使用Flink Runner先决条件及步骤"></a>使用Flink Runner先决条件及步骤</h2><h3 id="检查apache-beam对应版本所需要的flink版本"><a href="#检查apache-beam对应版本所需要的flink版本" class="headerlink" title="检查apache beam对应版本所需要的flink版本"></a>检查apache beam对应版本所需要的flink版本</h3><p>方式一：(推荐)<br>github上查找beam项目，找到指定版本的flink runner的pom.xml文件，检查flink.version版本<br><a href="https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml" target="_blank" rel="external">https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">&lt;properties&gt;</div><div class="line">    &lt;flink.version&gt;1.2.1&lt;/flink.version&gt;</div><div class="line">&lt;/properties&gt;</div></pre></td></tr></table></figure></p>
<p>方式二：<br>官方所说的通过mvn命令查询支持的flink版本<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">$ mvn dependency:tree -Pflink-runner |grep flink</div><div class="line">...</div><div class="line">[INFO] |  +- org.apache.flink:flink-streaming-java_2.10:jar:1.1.2:runtime</div><div class="line">...</div></pre></td></tr></table></figure></p>
<a id="more"></a>
<h3 id="下载，安装flink"><a href="#下载，安装flink" class="headerlink" title="下载，安装flink"></a>下载，安装flink</h3><h4 id="下载链接："><a href="#下载链接：" class="headerlink" title="下载链接："></a>下载链接：</h4><p><a href="http://archive.apache.org/dist/flink/flink-1.2.1/flink-1.2.1-bin-hadoop24-scala_2.10.tgz" target="_blank" rel="external">flink-1.2.1-bin-hadoop24-scala_2.10.tgz</a></p>
<h4 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h4><p>flink安装可以参考官方的<a href="https://ci.apache.org/projects/flink/flink-docs-release-1.3/quickstart/setup_quickstart.html" target="_blank" rel="external">QuickStart</a>文档进行安装(测试只需要安装local模式)。</p>
<h2 id="引入maven依赖"><a href="#引入maven依赖" class="headerlink" title="引入maven依赖"></a>引入maven依赖</h2><p>使用java作为开发语言，需要在项目的pom.xml文件中加入此依赖<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">&lt;dependency&gt;</div><div class="line">  &lt;groupId&gt;org.apache.beam&lt;/groupId&gt;</div><div class="line">  &lt;artifactId&gt;beam-runners-flink_2.10&lt;/artifactId&gt;</div><div class="line">  &lt;version&gt;2.0.0&lt;/version&gt;</div><div class="line">  &lt;scope&gt;runtime&lt;/scope&gt;</div><div class="line">&lt;/dependency&gt;</div></pre></td></tr></table></figure></p>
<h2 id="使用flink-runner执行pipeline"><a href="#使用flink-runner执行pipeline" class="headerlink" title="使用flink runner执行pipeline"></a>使用flink runner执行pipeline</h2><p>apache beam使用flink runner通过-P指定<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ mvn package -Pflink-runner</div></pre></td></tr></table></figure></p>
<p>下面是官方给的一个例子<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">$ mvn <span class="built_in">exec</span>:java -Dexec.mainClass=org.apache.beam.examples.WordCount \</div><div class="line">    -Pflink-runner \</div><div class="line">    -Dexec.args=<span class="string">"--runner=FlinkRunner \</span></div><div class="line">      --inputFile=/path/to/pom.xml \</div><div class="line">      --output=/path/to/counts \</div><div class="line">      --flinkMaster=&lt;flink master url&gt; \</div><div class="line">      --filesToStage=target/word-count-beam--bundled-0.1.jar"</div></pre></td></tr></table></figure></p>
<p>注：<br>–flinkMaster:指定flink jobmanager访问地址，本地模式为localhost:6123;<br>–filesToStage:指定运行的jar包<br>以下两个参数为pipeline options提供给flink runner的内置参数，更多内置参数请点击<a href="https://beam.apache.org/documentation/runners/flink/" target="_blank" rel="external">这里</a>查阅   </p>
<h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><h3 id="依赖包"><a href="#依赖包" class="headerlink" title="依赖包"></a>依赖包</h3><p>将以下以来包放入flink lib目录下<br><div class="note info"><p> beam-runners-flink_2.10-2.0.0.jar<br>beam-sdks-java-core-2.0.0.jar<br>beam-sdks-java-io-kafka-2.0.0.jar<br>kafka-clients-0.10.1.0.jar<br>kafka_2.10-0.8.2.2.jar<br>beam-runners-core-java-2.0.0.jar<br>spring-core-4.3.6.RELEASE.jar<br>spring-expression-4.3.6.RELEASE.jar </p>
</div></p>
<h3 id="问题：apache-beam-2-0-0与apache-flink1-3-0版本问题"><a href="#问题：apache-beam-2-0-0与apache-flink1-3-0版本问题" class="headerlink" title="问题：apache beam 2.0.0与apache flink1.3.0版本问题"></a>问题：apache beam 2.0.0与apache flink1.3.0版本问题</h3><p>apache beam 2.0.0的runner flink是基于flink 1.2.1版本编译的，而flink1.3.0版本删除了JobSnapshottingSettings类，导致用flink1.3.0运行的时候抛ClassNotFoundException异常。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">java.lang.ClassNotFoundException: org.apache.flink.runtime.jobgraph.tasks.JobSnapshottingSettings</div><div class="line">    at java.net.URLClassLoader.findClass(URLClassLoader.java:381)</div><div class="line">    at java.lang.ClassLoader.loadClass(ClassLoader.java:424)</div><div class="line">    at sun.misc.Launcher<span class="variable">$AppClassLoader</span>.loadClass(Launcher.java:331)</div><div class="line">    ... (省略部分日志)</div></pre></td></tr></table></figure></p>
<p>解决方法：</p>
<ul>
<li>如果想使用最新的flink1.3.0，建议直接从github下载源码自行编译，目前apache beam的master分支已经是采用flink1.3.0版本。</li>
<li>采用flink1.2.1版本运行程序</li>
</ul>
<p>参考链接：<br><a href="https://beam.apache.org/documentation/runners/flink/" target="_blank" rel="external">https://beam.apache.org/documentation/runners/flink/</a><br><a href="https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml" target="_blank" rel="external">https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;使用Flink-Runner先决条件及步骤&quot;&gt;&lt;a href=&quot;#使用Flink-Runner先决条件及步骤&quot; class=&quot;headerlink&quot; title=&quot;使用Flink Runner先决条件及步骤&quot;&gt;&lt;/a&gt;使用Flink Runner先决条件及步骤&lt;/h2&gt;&lt;h3 id=&quot;检查apache-beam对应版本所需要的flink版本&quot;&gt;&lt;a href=&quot;#检查apache-beam对应版本所需要的flink版本&quot; class=&quot;headerlink&quot; title=&quot;检查apache beam对应版本所需要的flink版本&quot;&gt;&lt;/a&gt;检查apache beam对应版本所需要的flink版本&lt;/h3&gt;&lt;p&gt;方式一：(推荐)&lt;br&gt;github上查找beam项目，找到指定版本的flink runner的pom.xml文件，检查flink.version版本&lt;br&gt;&lt;a href=&quot;https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/apache/beam/blob/v2.0.0/runners/flink/pom.xml&lt;/a&gt;&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;properties&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;    &amp;lt;flink.version&amp;gt;1.2.1&amp;lt;/flink.version&amp;gt;&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;&amp;lt;/properties&amp;gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;方式二：&lt;br&gt;官方所说的通过mvn命令查询支持的flink版本&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;2&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;3&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;4&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ mvn dependency:tree -Pflink-runner |grep flink&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;...&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;[INFO] |  +- org.apache.flink:flink-streaming-java_2.10:jar:1.1.2:runtime&lt;/div&gt;&lt;div class=&quot;line&quot;&gt;...&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
      <category term="apache flink" scheme="http://yoursite.com/tags/apache-flink/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam:便携式并行数据处理</title>
    <link href="http://yoursite.com/2017/06/02/apache-beam-protable-and-parallel-data-processing/"/>
    <id>http://yoursite.com/2017/06/02/apache-beam-protable-and-parallel-data-processing/</id>
    <published>2017-06-02T08:24:47.000Z</published>
    <updated>2017-06-02T08:27:43.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Apache-Beam-Portable-and-Parallel-Data-Processing"><a href="#Apache-Beam-Portable-and-Parallel-Data-Processing" class="headerlink" title="Apache Beam: Portable and Parallel Data Processing"></a>Apache Beam: Portable and Parallel Data Processing</h2><iframe width="560" height="315" src="https://www.youtube.com/embed/owTuuVt6Oro" frameborder="0" allowfullscreen></iframe>

<h2 id="概念说明"><a href="#概念说明" class="headerlink" title="概念说明"></a>概念说明</h2><p>在我们做数据流处理的过程中，经常会遇到的一个问题：网络延迟。当然对于无序的数据流来说，网络延迟所带来的数据乱序对结果是不会有太大影响的。但是对于数据顺序有要求的应用，则会导致数据不一致等棘手的问题。<br><a id="more"></a><br>官方给出的一个例子中，包含两个维度：</p>
<ul>
<li>事件事件(Event Time):  事件发生时间</li>
<li>处理事件(Processing Time):事件处理时间<br><img src="/images/beam-processingTime-eventTime.png" alt="img"><br>上图中，横轴代表事件发生时间，纵轴代表事件处理事件。在做数据处理的时候，我们往往所理想的情况是数据一出来就被处理完成，图中虚线则代表了这种理想情况。<br>注：离虚线越近的事件延迟低(图中突出的3事件)，反之则延迟高(图中突出的9事件)</li>
</ul>
<h2 id="Beam模型围绕的四个关键问题"><a href="#Beam模型围绕的四个关键问题" class="headerlink" title="Beam模型围绕的四个关键问题"></a>Beam模型围绕的四个关键问题</h2><h3 id="计算的结果是什么？（What-results-are-calculated-）"><a href="#计算的结果是什么？（What-results-are-calculated-）" class="headerlink" title="计算的结果是什么？（What results are calculated?）"></a>计算的结果是什么？（What results are calculated?）</h3><p>例如，Sum、Join或是机器学习中训练学习模型等。在Beam SDK中由Pipeline中的操作符指定。<br>下图展示一个sum示例，累计12:00-12:10分的数字累加。<br><img src="/images/beam-what.jpg" alt="img"><br>对应Beam代码如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>通过input.apply()方法，通过beam提供的transforms的Sum进行数据统计<br><img src="/images/what-is-being-computed.png" alt="img"></p>
<h3 id="数据在什么范围中计算？-Where-in-event-time-are-result-calculated"><a href="#数据在什么范围中计算？-Where-in-event-time-are-result-calculated" class="headerlink" title="数据在什么范围中计算？(Where in event time are result calculated?)"></a>数据在什么范围中计算？(Where in event time are result calculated?)</h3><p>例如，基于Process-Time的时间窗口，基于Event-Time的时间窗口、滑动窗口等。在BeamSDK中由Pipeline中的窗口指定<br>假如我们现在想在事件时间横轴上统计每个2分钟时间窗口的整数累加值，即完成如下图动画所示的效果<br><img src="/images/beam-where.jpg" alt="img"><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2))))</div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>Beam 自动为每个时间窗口创建一个小的批处理作业，在处理时间纵轴 12:10 的时候触发计算。但是这样，我们只能等到最后的一个时间点（12:10）才能得到计算结果。</p>
<p>所支持的窗口列表如下：<br><img src="/images/where-in-event-time.png" alt="img"></p>
<h3 id="何时将结果数据落地？-When-in-processing-time-are-results-materialized"><a href="#何时将结果数据落地？-When-in-processing-time-are-results-materialized" class="headerlink" title="何时将结果数据落地？(When in processing time are results materialized?)"></a>何时将结果数据落地？(When in processing time are results materialized?)</h3><p>例如，在1小时的Event-Time时间窗口中，每隔2分钟，将当前窗口计算结果输出。</p>
<p>在上个问题中，我们以2分钟为间隔，输出每2分钟的统计结果。但是如果用户想提前将结果写入统计结果，那么我们就要对代码做一定的修改。<br><img src="/images/beam-when.jpg" alt="img"><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</div><div class="line">            .triggering(AtWatermark()))            </div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>此处引入了触发器(Trigger)以及水平线(Watermark)，触发器(Trigger)决定何时将计算结果发射出去，发射太早会丢失一部分数据，丧失精确性，发射太晚会导致延迟变长，而且会囤积大量数据，何时触发器(Trigger)是由水位线(Watermark)来决定的，在Beam SDK中由Pipeline中的水位线和触发器指定</p>
<p>所支持的触发器(Trigger)列表如下：<br><img src="/images/when-in-processing-time.png" alt="img"></p>
<h3 id="如何对结果进行改进修正？-How-do-refinements-of-results-relate"><a href="#如何对结果进行改进修正？-How-do-refinements-of-results-relate" class="headerlink" title="如何对结果进行改进修正？(How do refinements of results relate?)"></a>如何对结果进行改进修正？(How do refinements of results relate?)</h3><p>例如，将迟到数据计算增量结果输出，或是将迟到数据计算结果和窗口内数据计算结果合并成全量结果输出。在Beam SDK中由Accumulation指定</p>
<p>从上个问题的动图中可以看出，虽然我们解决了提前写入事件窗口的统计结果提前写入的问题，但是从动图上可以看出，结果统计遗漏了9这个事件，接下来这步我们就要解决这个问题。<br><img src="/images/beam-how.jpg" alt="img"><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">PCollection&lt;KV&lt;String,Integer&gt;&gt; scores = input</div><div class="line">    .apply(Window.into(FixedWindows.of(Duration.standardMinutes(2)))</div><div class="line">           .triggering(AtWatermark()</div><div class="line">              .withEarlyFirings(AtPeriod(Duration.standardMinutes(1)))</div><div class="line">              .withLateFirings(AtCount(1)))</div><div class="line">           .accumulatingFiredPanes())            </div><div class="line">    .apply(Sum.integersPerKey());</div></pre></td></tr></table></figure></p>
<p>所支持的改进修正功能列表如下：<br><img src="/images/How-do-refinements-relate.png" alt="img"></p>
<p>参考连接：<br><a href="https://beam.apache.org/documentation/runners/capability-matrix/#cap-summary-what" target="_blank" rel="external">https://beam.apache.org/documentation/runners/capability-matrix/#cap-summary-what</a><br><a href="http://www.jianshu.com/p/357bf071d017" target="_blank" rel="external">http://www.jianshu.com/p/357bf071d017</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Apache-Beam-Portable-and-Parallel-Data-Processing&quot;&gt;&lt;a href=&quot;#Apache-Beam-Portable-and-Parallel-Data-Processing&quot; class=&quot;headerlink&quot; title=&quot;Apache Beam: Portable and Parallel Data Processing&quot;&gt;&lt;/a&gt;Apache Beam: Portable and Parallel Data Processing&lt;/h2&gt;&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/owTuuVt6Oro&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&quot;概念说明&quot;&gt;&lt;a href=&quot;#概念说明&quot; class=&quot;headerlink&quot; title=&quot;概念说明&quot;&gt;&lt;/a&gt;概念说明&lt;/h2&gt;&lt;p&gt;在我们做数据流处理的过程中，经常会遇到的一个问题：网络延迟。当然对于无序的数据流来说，网络延迟所带来的数据乱序对结果是不会有太大影响的。但是对于数据顺序有要求的应用，则会导致数据不一致等棘手的问题。&lt;br&gt;
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>Apache Beam 介绍</title>
    <link href="http://yoursite.com/2017/06/02/apache-beam-introduce/"/>
    <id>http://yoursite.com/2017/06/02/apache-beam-introduce/</id>
    <published>2017-06-02T08:23:12.000Z</published>
    <updated>2017-06-02T08:27:49.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>作为一名大数据开发者，不得不说自从hadoop问世之后，接连而来的各种各样的大数据处理框架层出不穷，而我们则要不断的去学习，运用不同的技术、框架、api，甚至是开发语言以及sdk，去开发项目功能，解决项目问题。</p>
<ul>
<li>平台迁移问题：根据项目的需求，技术的更新迭代，项目性能的要求等等，同样的业务要在不同的框架上运行，可能你就要花费很长一段时间去学习新的框架，新的api。</li>
<li>开发工具难抉择：近两年开启的开源大潮，为大数据开发者提供了十分富余的工具。但这同时也增加了开发者选择合适的工具的难度，尤其对于新入行的开发者来说。这很可能拖慢、甚至阻碍开源工具的发展<a id="more"></a>
Apache Beam（原名Google DataFlow）是Google在2016年2月份贡献给Apache基金会的Apache孵化项目，被认为是继MapReduce，GFS和BigQuery等之后，Google在大数据处理领域对开源社区的又一个非常大的贡献。Apache Beam的主要目标是统一批处理和流处理的编程范式，为无限，乱序，web-scale的数据集处理提供简单灵活，功能丰富以及表达能力十分强大的SDK。<br>Apache Beam项目重点在于数据处理的编程范式和接口定义，并不涉及具体执行引擎的实现。<br>Apache Beam希望基于Beam开发的数据处理程序可以执行在任意的分布式计算引擎上<br><img src="/images/bigdata.png" alt="img"></li>
</ul>
<h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul>
<li>统一(Unified)：<br> 对于批处理和流式处理，使用单一的编程模型，能够实现批处理（Batch processing）、流处理（Streaming Processing），通常的做法是把待处理的数据集（Dataset）统一，一般会把有界（Bound）数据集作为无界（Unbound）数据集的一种特殊情况来看待，比如Apache Flink便是按照这种方式处理，在差异化的API层之上构建一个统一的API层。</li>
<li>可移植(Portable)：<br> 在多个不同的计算环境下，都能够执行已经定义好的数据处理Pipeline。也就是说，对数据集处理的定义（即构建的Data Pipeline），与最终所要Deploy的执行环境完全无关。这对实现数据处理的企业是非常友好的，当下数据处理新技术不断涌现，企业数据处理平台也为了能够与时俱进并提高处理效率，当然希望在底层计算平台升级的过程中无需重写上层已定义的Data Pipeline。<br> 目前，Apache Beam项目开发整体来看还处在初期，初步决定底层执行环境支持主流的计算平台：<br> Apache Apex、Apache Flink、Apache Spark、Google Cloud Dataflow。实际上，Apache Beam的这种统一编程模型，可以支持任意的计算引擎，通过Data Pipeline层与执行引擎层之间开发一个类似Driver的连接器即可实现。</li>
<li>可拓展(Extensible)：可以实现和分享更多的新SDK、IO连接器、转换操作库等；</li>
</ul>
<!-- more -->
<h2 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h2><h3 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h3><p>管道，包装数据处理流程任务</p>
<h3 id="PCollection"><a href="#PCollection" class="headerlink" title="PCollection"></a>PCollection</h3><p>分布式数据集，PCollection是管道中每个步骤的输入、输出</p>
<h3 id="Transforms"><a href="#Transforms" class="headerlink" title="Transforms"></a>Transforms</h3><p>管道中的每个步骤，它接收一个或者若干个输入PCollection，进行处理后，输出PCollection</p>
<h3 id="I-O-sources-and-sinks"><a href="#I-O-sources-and-sinks" class="headerlink" title="I/O sources and sinks"></a>I/O sources and sinks</h3><p>source和sink用于提供数据的输入和输出端点<br>目前支持如下：</p>
<h4 id="内嵌-I-O-转换"><a href="#内嵌-I-O-转换" class="headerlink" title="内嵌 I/O 转换"></a>内嵌 I/O 转换</h4><table>
<thead>
<tr>
<th>Language</th>
<th>File-based</th>
<th>Messaging</th>
<th>Database</th>
</tr>
</thead>
<tbody>
<tr>
<td>Java</td>
<td>AvroIO<br>Apache Hadoop File System<br>TextIO<br>XML</td>
<td>JMS<br>Apache Kafka<br>Amazon Kinesis<br>Google Cloud PubSub</td>
<td>Apache Hadoop InputFormat<br>Apache HBase<br>MongoDB<br>JDBC<br>Google BigQuery<br>Google Cloud Bigtable<br>Google Cloud Datastore</td>
</tr>
<tr>
<td>Python</td>
<td>avroio<br>textio</td>
<td></td>
<td>Google BigQuery<br>Google Cloud Datastore</td>
</tr>
</tbody>
</table>
<h4 id="拓展-I-O-转换"><a href="#拓展-I-O-转换" class="headerlink" title="拓展 I/O 转换"></a>拓展 I/O 转换</h4><table>
<thead>
<tr>
<th>Name</th>
<th>Language</th>
<th>JIRA</th>
</tr>
</thead>
<tbody>
<tr>
<td>AMQP</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1237" target="_blank" rel="external">BEAM-1237</a></td>
</tr>
<tr>
<td>Apache Cassandra</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-245" target="_blank" rel="external">BEAM-245</a></td>
</tr>
<tr>
<td>Apache DistributedLog</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-607" target="_blank" rel="external">BEAM-607</a></td>
</tr>
<tr>
<td>Apache Hive</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1158" target="_blank" rel="external">BEAM-1158</a></td>
</tr>
<tr>
<td>Apache Parquet</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-214" target="_blank" rel="external">BEAM-214</a></td>
</tr>
<tr>
<td>Apache Solr</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1236" target="_blank" rel="external">BEAM-1236</a></td>
</tr>
<tr>
<td>Apache Sqoop</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-67" target="_blank" rel="external">BEAM-67</a></td>
</tr>
<tr>
<td>Couchbase</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1893" target="_blank" rel="external">BEAM-1893</a></td>
</tr>
<tr>
<td>JSON</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1581" target="_blank" rel="external">BEAM-1581</a></td>
</tr>
<tr>
<td>Memcached</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1678" target="_blank" rel="external">BEAM-1678</a></td>
</tr>
<tr>
<td>Neo4j</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1857" target="_blank" rel="external">BEAM-1857</a></td>
</tr>
<tr>
<td>Redis</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1017" target="_blank" rel="external">BEAM-1017</a></td>
</tr>
<tr>
<td>RabbitMQ</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1240" target="_blank" rel="external">BEAM-1240</a></td>
</tr>
<tr>
<td>RestIO</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1946" target="_blank" rel="external">BEAM-1946</a></td>
</tr>
<tr>
<td>TikaIO</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-2328" target="_blank" rel="external">BEAM-2328</a></td>
</tr>
<tr>
<td>Cloud Spanner</td>
<td>Java</td>
<td><a href="https://issues.apache.org/jira/browse/BEAM-1542" target="_blank" rel="external">BEAM-1542</a></td>
</tr>
</tbody>
</table>
<h2 id="基本架构"><a href="#基本架构" class="headerlink" title="基本架构"></a>基本架构</h2><h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="/images/apache-beam-framework.png" alt="img"><br>通过上图，我们可以清楚的知道，执行一个流程分以下步骤：</p>
<ul>
<li>End Users：选择一种你熟悉的编程语言提交应用</li>
<li>SDK Writers：该编程语言必须是 Beam 模型支持的</li>
<li>Library Writers：转换成Beam模型的格式</li>
<li>Runner Writers：在分布式环境下处理并支持Beam的数据处理管道</li>
<li>IO Providers：在Beam的数据处理管道上运行所有的应用</li>
<li>DSL Writers：创建一个高阶的数据处理管道<h3 id="Beam核心组成部分"><a href="#Beam核心组成部分" class="headerlink" title="Beam核心组成部分"></a>Beam核心组成部分</h3></li>
<li>Beam SDK<br> Beam SDK提供一个统一的编程接口给到上层应用的开发者，开发者不需要了解底层的具体的大数据平台的开发接口是什么，直接通过Beam SDK的接口，就可以开发数据处理的加工流程，不管输入是用于批处理的有限数据集，还是流式的无限数据集。对于有限或无限的输入数据，Beam SDK都使用相同的类来表现，并且使用相同的转换操作进行处理。Beam SDK可以有不同编程语言的实现，目前已经完整地提供了Java，python的SDK还在开发过程中，相信未来会有更多不同的语言的SDK会发布出来。</li>
<li>Beam Pipeline Runner<br> Beam Pipeline Runner将用户用Beam模型定义开发的处理流程翻译成底层的分布式数据处理平台支持的运行时环境。在运行Beam程序时，需要指明底层的正确Runner类型。针对不同的大数据平台，会有不同的Runner。目前Flink、Spark、Apex以及谷歌的Cloud DataFlow都有支持Beam的Runner。</li>
</ul>
<h3 id="语言-Language"><a href="#语言-Language" class="headerlink" title="语言(Language)"></a>语言(Language)</h3><p><img src="/images/beam_architecture.png" alt="img"></p>
<h3 id="运行器-Runner"><a href="#运行器-Runner" class="headerlink" title="运行器(Runner)"></a>运行器(Runner)</h3><p><img src="/images/beam-workers.jpg" alt="img"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Apache Beam的Beam Model对无限乱序数据流的数据处理进行了非常优雅的抽象，“WWWH”四个维度对数据处理的描述，非常清晰与合理，Beam Model在统一了对无限数据流和有限数据集的处理模式的同时，也明确了对无限数据流的数据处理方式的编程范式，扩大了流处理系统可应用的业务范围，例如，Event-Time/Session窗口的支持，乱序数据的处理支持等。Apache Flink，Apache Spark Streaming等项目的API设计均越来越多的借鉴或参考了Apache Beam Model，且作为Beam Runner的实现，与Beam SDK的兼容度也越来越高。<br>目前apache beam的开发处于初步阶段，对python的支持还在开发中，对java的支持的内容相对比较丰富，支持的runner也会逐步增加，实现平台迁移的可移植，降低／解决大数据开发者框架选择的问题。</p>
<p>参考链接：<br><a href="https://www.infoq.com/presentations/apache-beam" target="_blank" rel="external">https://www.infoq.com/presentations/apache-beam</a><br><a href="https://beam.apache.org/documentation/io/built-in/" target="_blank" rel="external">https://beam.apache.org/documentation/io/built-in/</a><br><a href="http://www.cnblogs.com/smartloli/p/6685106.html" target="_blank" rel="external">http://www.cnblogs.com/smartloli/p/6685106.html</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;背景介绍&quot;&gt;&lt;a href=&quot;#背景介绍&quot; class=&quot;headerlink&quot; title=&quot;背景介绍&quot;&gt;&lt;/a&gt;背景介绍&lt;/h2&gt;&lt;p&gt;作为一名大数据开发者，不得不说自从hadoop问世之后，接连而来的各种各样的大数据处理框架层出不穷，而我们则要不断的去学习，运用不同的技术、框架、api，甚至是开发语言以及sdk，去开发项目功能，解决项目问题。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平台迁移问题：根据项目的需求，技术的更新迭代，项目性能的要求等等，同样的业务要在不同的框架上运行，可能你就要花费很长一段时间去学习新的框架，新的api。&lt;/li&gt;
&lt;li&gt;开发工具难抉择：近两年开启的开源大潮，为大数据开发者提供了十分富余的工具。但这同时也增加了开发者选择合适的工具的难度，尤其对于新入行的开发者来说。这很可能拖慢、甚至阻碍开源工具的发展
    
    </summary>
    
      <category term="apache beam" scheme="http://yoursite.com/categories/apache-beam/"/>
    
    
      <category term="apache beam" scheme="http://yoursite.com/tags/apache-beam/"/>
    
  </entry>
  
  <entry>
    <title>常用工具库</title>
    <link href="http://yoursite.com/2017/05/31/common-tools-repository/"/>
    <id>http://yoursite.com/2017/05/31/common-tools-repository/</id>
    <published>2017-05-31T15:05:05.000Z</published>
    <updated>2017-06-01T07:12:26.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Maven-Search-Repository"><a href="#Maven-Search-Repository" class="headerlink" title="Maven Search Repository"></a>Maven Search Repository</h2><p>一直以来都是以maven来开发项目，这里提供两个maven查询库地址。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ http://search.maven.org</div></pre></td></tr></table></figure></p>
<p>More info: <a href="http://search.maven.org" target="_blank" rel="external">Link</a><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ http://mvnrepository.com</div></pre></td></tr></table></figure></p>
<p>More info: <a href="http://mvnrepository.com" target="_blank" rel="external">Link</a><br><a id="more"></a></p>
<h2 id="Jsoup-Tool"><a href="#Jsoup-Tool" class="headerlink" title="Jsoup Tool"></a>Jsoup Tool</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ https://try.jsoup.org</div></pre></td></tr></table></figure>
<p>More info: <a href="https://try.jsoup.org" target="_blank" rel="external">Link</a></p>
<h2 id="Ali-Maven-Source-Repository"><a href="#Ali-Maven-Source-Repository" class="headerlink" title="Ali Maven Source Repository"></a>Ali Maven Source Repository</h2><p>maven官网提供的repository下载速度过慢，影响工作效率，这里提供一个ali maven repository给大家使用.<br><a href="/files/settings.xml">ali maven settings file</a><br>如需要修改repository的存放位置，可以修改以下配置<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ &lt;<span class="built_in">local</span>Repository&gt;<span class="variable">$&#123;user.home&#125;</span>/.m2/repository&lt;/<span class="built_in">local</span>Repository&gt;</div></pre></td></tr></table></figure></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;Maven-Search-Repository&quot;&gt;&lt;a href=&quot;#Maven-Search-Repository&quot; class=&quot;headerlink&quot; title=&quot;Maven Search Repository&quot;&gt;&lt;/a&gt;Maven Search Repository&lt;/h2&gt;&lt;p&gt;一直以来都是以maven来开发项目，这里提供两个maven查询库地址。&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ http://search.maven.org&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a href=&quot;http://search.maven.org&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Link&lt;/a&gt;&lt;br&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ http://mvnrepository.com&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;More info: &lt;a href=&quot;http://mvnrepository.com&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Link&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="tools" scheme="http://yoursite.com/categories/tools/"/>
    
    
      <category term="maven" scheme="http://yoursite.com/tags/maven/"/>
    
      <category term="jsoup" scheme="http://yoursite.com/tags/jsoup/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://yoursite.com/2017/05/02/hello-world/"/>
    <id>http://yoursite.com/2017/05/02/hello-world/</id>
    <published>2017-05-02T08:23:12.000Z</published>
    <updated>2017-06-02T08:43:25.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a><br><a id="more"></a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Writing&lt;/a&gt;&lt;br&gt;
    
    </summary>
    
      <category term="Testing" scheme="http://yoursite.com/categories/Testing/"/>
    
    
      <category term="Hello" scheme="http://yoursite.com/tags/Hello/"/>
    
  </entry>
  
</feed>
